Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol
Aggelos Kiayias∗ Alexander Russell† Bernardo David‡ Roman Oliynykov§
August 21, 2017
Abstract
We present “Ouroboros”, the first blockchain protocol based on proof of stake with rigorous security guarantees. We establish security properties for the protocol comparable to
those achieved by the bitcoin blockchain protocol. As the protocol provides a “proof of stake”
blockchain discipline, it offers qualitative efficiency advantages over blockchains based on proof
of physical resources (e.g., proof of work). We also present a novel reward mechanism for incentivizing Proof of Stake protocols and we prove that, given this mechanism, honest behavior
is an approximate Nash equilibrium, thus neutralizing attacks such as selfish mining. We also
present initial evidence of the practicality of our protocol in real world settings by providing
experimental results on transaction confirmation and processing.
1 Introduction
A primary consideration regarding the operation of blockchain protocols based on proof of work
(PoW)—such as bitcoin [30]—is the energy required for their execution. At the time of this writing, generating a single block on the bitcoin blockchain requires a number of hashing operations
exceeding 260, which results in striking energy demands. Indeed, early calculations indicated that
the energy requirements of the protocol were comparable to that of a small country [32].
This state of affairs has motivated the investigation of alternative blockchain protocols that
would obviate the need for proof of work by substituting it with another, more energy efficient,
mechanism that can provide similar guarantees. It is important to point out that the proof of work
mechanism of bitcoin facilitates a type of randomized “leader election” process that elects one of
the miners to issue the next block. Furthermore, provided that all miners follow the protocol, this
selection is performed in a randomized fashion proportionally to the computational power of each
miner. (Deviations from the protocol may distort this proportionality as exemplified by “selfish
mining” strategies [21, 38].)
A natural alternative mechanism relies on the notion of “proof of stake” (PoS). Rather than
miners investing computational resources in order to participate in the leader election process, they
instead run a process that randomly selects one of them proportionally to the stake that each
possesses according to the current blockchain ledger.
In effect, this yields a self-referential blockchain discipline: maintaining the blockchain relies on
the stakeholders themselves and assigns work to them (as well as rewards) based on the amount
of stake that each possesses as reported in the ledger. Aside from this, the discipline should make
no further “artificial” computational demands on the stakeholders. In some sense, this sounds
ideal; however, realizing such a proof-of-stake protocol appears to involve a number of definitional,
technical, and analytic challenges.
Previous work. The concept of PoS has been discussed extensively in the bitcoin forum.1 Proofof-stake based blockchain design has been more formally studied by Bentov et al., both in conjunction with PoW [5] as well as the sole mechanism for a blockchain protocol [4]. Although Bentov
et al. showed that their protocols are secure against some classes of attacks, they do not provide
a formal model for analysing PoS based protocols or security proofs relying on precise definitions.
Heuristic proof-of-stake based blockchain protocols have been proposed (and implemented) for a
number of cryptocurrencies.2 Being based on heuristic security arguments, these cryptocurrencies
have been frequently found to be deficient from the point of view of security. See [4] for a discussion
of various attacks.
It is also interesting to contrast a PoS-based blockchain protocol with a classical consensus
blockchain that relies on a fixed set of authorities (see, e.g., [17]). What distinguishes a PoS-based
blockchain from those which assume static authorities is that stake changes over time and hence
the trust assumption evolves with the system.
Another alternative to PoW is the concept of proof of space [2, 20], which has been specifically
investigated in the context of blockchain protocols [33]. In a proof of space setting, a “prover”
wishes to demonstrate the utilization of space (storage / memory); as in the case of a PoW, this
utilizes a physical resource but can be less energy demanding over time. A related concept is proof
of space-time (PoST) [28]. In all these cases, however, an expensive physical resource (either storage
or computational power) is necessary.
The PoS Design challenge. A fundamental problem for PoS-based blockchain protocols is to
simulate the leader election process. In order to achieve a fair randomized election among stakeholders, entropy must be introduced into the system, and mechanisms to introduce entropy may be
prone to manipulation by the adversary. For instance, an adversary controlling a set of stakeholders
may attempt to simulate the protocol execution trying different sequences of stakeholder participants so that it finds a protocol continuation that favors the adversarial stakeholders. This leads
to a so called “grinding” vulnerability, where adversarial parties may use computational resources
to bias the leader election.
Our Results. We present “Ouroboros”, a provably secure proof of stake system. To the best of
our knowledge this is the first blockchain protocol of its kind with a rigorous security analysis. In
more detail, our results are as follows.
First, we provide a model that formalizes the problem of realizing a PoS-based blockchain protocol. The model we introduce is in the spirit of [24], focusing on persistence and liveness, two formal
properties of a robust transaction ledger. Persistence states that once a node of the system proclaims a certain transaction as “stable”, the remaining nodes, if queried and responding honestly
will also report it as stable. Here, stability is to be understood as a predicate that will be parameterized by some security parameter k that will affect the certainty with which the property holds.
(E.g., “more than k blocks deep”.) Liveness ensures that once an honestly generated transaction
has been made available for a sufficient amount of time to the network nodes, say u time steps,
it will become stable. The conjunction of liveness and persistence provides a robust transaction
ledger in the sense that honestly generated transactions are adopted and become immutable. Our
model is suitably amended to facilitate PoS-based dynamics.
Second, we describe a novel blockchain protocol based on PoS. Our protocol assumes that parties
can freely create accounts and receive and make payments, and that stake shifts over time. We
utilize a (very simple) secure multiparty implementation of a coin-flipping protocol to produce the
randomness for the leader election process. This distinguishes our approach (and prevents so called
“grinding attacks”) from other previous solutions that either defined such values deterministically
based on the current state of the blockchain or used collective coin flipping as a way to introduce
entropy [4]. Also, unique to our approach is the fact that the system ignores round-to-round
stake modifications. Instead, a snapshot of the current set of stakeholders is taken in regular
intervals called epochs; in each such interval a secure multiparty computation takes place utilizing
the blockchain itself as the broadcast channel. Specifically, in each epoch a set of randomly selected
stakeholders form a committee which is then responsible for executing the coin-flipping protocol.
The outcome of the protocol determines the set of next stakeholders to execute the protocol in the
next epoch as well as the outcomes of all leader elections for the epoch.
Third, we provide a set of formal arguments establishing that no adversary can break persistence
and liveness. Our protocol is secure under a number of plausible assumptions: (1) the network
is synchronous in the sense that an upper bound can be determined during which any honest
stakeholder is able to communicate with any other stakeholder, (2) a number of stakeholders drawn
from the honest majority is available as needed to participate in each epoch, (3) the stakeholders
do not remain offline for long periods of time, (4) the adaptivity of corruptions is subject to a small
delay that is measured in rounds linear in the security parameter (or alternatively, the players
have access to a sender-anonymous broadcast channel). At the core of our security arguments is a
probabilistic argument regarding a combinatorial notion of “forkable strings” which we formulate,
prove and also verify experimentally. In our analysis we also distinguish covert attacks, a special
class of general forking attacks. “Covertness” here is interpreted in the spirit of covert adversaries
against secure multiparty computation protocols, cf. [3], where the adversary wishes to break the
protocol but prefers not to be caught doing so. We show that covertly forkable strings are a
subclass of the forkable strings with much smaller density; this permits us to provide two distinct
security arguments that achieve different trade-offs in terms of efficiency and security guarantees.
Our forkable string analysis is a natural and fairly general tool that can be applied as part of a
security argument the PoS setting.
Fourth, we turn our attention to the incentive structure of the protocol. We present a novel
reward mechanism for incentivizing the participants to the system which we prove to be an (approximate) Nash equilibrium. In this way, attacks like block withholding and selfish-mining [21, 38]
are mitigated by our design. The core idea behind the reward mechanism is to provide positive
payoff for those protocol actions that cannot be stifled by a coalition of parties that diverges from
the protocol. In this way, it is possible to show that, under plausible assumptions, namely that
certain protocol execution costs are small, following the protocol faithfully is an equilibrium when
all players are rational.
Fifth, we introduce a stake delegation mechanism that can be seamlessly added to our blockchain
protocol. Delegation is particularly useful in our context as we would like to allow our protocol
to scale even in a setting where the set of stakeholders is highly fragmented. In such cases, the
delegation mechanism can enable stakeholders to delegate their “voting rights”, i.e., the right
of participating in the committees running the leader selection protocol in each epoch. As in
liquid democracy, (a.k.a. delegative democracy [23]), stakeholders have the ability to revoke their
delegative appointment when they wish independently of each other.
Given our model and protocol description we also explore how various attacks considered in
practice can be addressed within our framework. Specifically, we discuss double spending attacks,
transaction denial attacks, 51% attacks, nothing-at-stake, desynchronization attacks and others.
Finally, we present evidence regarding the efficiency of our design. First we consider double spending
attacks. For illustrative purposes, we perform a comparison with Nakamoto’s analysis for bitcoin
regarding transaction confirmation time with assurance 99.9%. Against covert adversaries, the
transaction confirmation time is from 10 to 16 times faster than that of bitcoin, depending on the
adversarial hashing power; for general adversaries confirmation time is from 5 to 10 times faster.
Moreover, our concrete analysis of double-spending attacks relies on our combinatorial analysis of
forkable and covertly forkable strings and applies to a much broader class of adversarial behavior
than Nakamoto’s more simplified analysis.3 We then survey our prototype implementation and
report on benchmark experiments run in the Amazon cloud that showcase the power of our proof
of stake blockchain protocol in terms of performance.
Related Work. In parallel to the development of Ouroboros, a number of other protocols were
developed targeting various positions in the design space of distributed ledgers based on PoS.
Sleepy consensus [6] considers a fixed stakeholder distribution (i.e., stake does not evolve over
time) and targets a “mixed” corruption setting, where the adversary is allowed to be adaptive as
well as perform fail-stop and recover corruptions in addition to Byzantine faults. It is actually
straightforward to extend our analysis in this mixed corruption setting, cf. Remark 2; nevertheless,
the resulting security can be argued only in the “corruptions with delay” setting, and thus is
not fully adaptive. Snow White [7] addresses an evolving stakeholder distribution and uses a
corruption delay mechanism similar to ours for arguing security. Nevertheless, contrary to our
protocol, the Snow White design is susceptible to a “grinding” type of attack that can bias high
probability events in favor of the adversary. While this does not hurt security asymptotically, it
prevents a concrete parameterisation that does not take into account adversarial computing power.
Algorand [27] provides a distributed ledger following a Byzantine agreement per block approach
that can withstand adaptive corruptions. Given that agreement needs to be reached for each block,
such protocols will produce blocks at a rate substantially slower than a PoS blockchain (where the
slow down matches the expected length of the execution of the Byzantine agreement protocol) but
they are free of forks. In this respect, despite the existence of forks, blockchain protocols exhibit
the flexibility of permitting the clients to set the level of risk that they are willing to undertake,
allowing low risk profile clients to enjoy faster processing times in the optimistic sense. Finally,
Fruitchain [36] provides a reward mechanism and an approximate Nash equilibrium proof for a
PoW-based blockchain. We use a similar reward mechanism at the blockchain level, nevertheless
our underlying mechanics are different since we have to operate in a PoS setting. The core of the
idea is to provide a PoS analogue of “endorsing” inputs in a fair proportion using the same logic as
the PoW-based byzantine agreement protocol for honest majority from [24].
Paper overview. We lay out the basic model in Sec. 2. To simplify the analysis of our protocol,
we present it in four stages that are outlined in Sec. 3. In short, in Sec. 4 we describe and analyze
the protocol in the static setting; we then transition to the dynamic setting in Sec. 5. Our incentive
mechanism and the equilibrium argument are presented in Sec. 7. We then present the protocol
enhancement with anonymous channels in Sec. 6 and with a delegation mechanism in Sec. 8.
Following this, in Sec. 9 we discuss the resilience of the protocol under various particular attacks
of interest. In Sec. 10 we discuss transaction confirmation times as well as general performance
results obtained from a prototype implementation running in the Amazon cloud.
2 Model
Time, slots, and synchrony. We consider a setting where time is divided into discrete units
called slots. A ledger, described in more detail below, associates with each time slot (at most) one
ledger block. Players are equipped with (roughly synchronized) clocks that indicate the current
slot. This will permit them to carry out a distributed protocol intending to collectively assign a
block to this current slot. In general, each slot slr is indexed by an integer r ∈ {1, 2, . . .}, and we
assume that the real time window that corresponds to each slot has the following properties.
• The current slot is determined by a publicly-known and monotonically increasing function of
current time.
• Each player has access to the current time. Any discrepancies between parties’ local time are
insignificant in comparison with the length of time represented by a slot.
• The length of the time window that corresponds to a slot is sufficient to guarantee that
any message transmitted by an honest party at the beginning of the time window will be
received by any other honest party by the end of that time window (even accounting for
small inconsistencies in parties’ local clocks). In particular, while network delays may occur,
they never exceed the slot time window.
Transaction Ledger Properties. A protocol Π implements a robust transaction ledger provided
that the ledger that Π maintains is divided into “blocks” (assigned to time slots) that determine the
order with which transactions are incorporated in the ledger. It should also satisfy the following
two properties.
• Persistence. Once a node of the system proclaims a certain transaction tx as stable, the
remaining nodes, if queried, will either report tx in the same position in the ledger or will not
report as stable any transaction in conflict to tx. Here the notion of stability is a predicate
that is parameterized by a security parameter k; specifically, a transaction is declared stable
if and only if it is in a block that is more than k blocks deep in the ledger.
• Liveness. If all honest nodes in the system attempt to include a certain transaction, then
after the passing of time corresponding to u slots (called the transaction confirmation time),
all nodes, if queried and responding honestly, will report the transaction as stable.
In [26, 35] it was shown that persistence and liveness can be derived from the following three
elementary properties provided that protocol Π derives the ledger from a data structure in the form
of a blockchain.
• Common Prefix (CP); with parameters k ∈ N. The chains C1, C2 possessed by two
honest parties at the onset of the slots sl1 < sl2 are such that C
dk
1  C2, where C
dk
1 denotes
the chain obtained by removing the last k blocks from C1, and  denotes the prefix relation.
• Chain Quality (CQ); with parameters µ ∈ (0, 1] and ` ∈ N. Consider any portion of
length at least ` of the chain possessed by an honest party at the onset of a round; the ratio of
blocks originating from the adversary is at most 1−µ. We call µ the chain quality coefficient.
• Chain Growth (CG); with parameters τ ∈ (0, 1], s ∈ N. Consider the chains C1, C2
possessed by two honest parties at the onset of two slots sl1, sl2 with sl2 at least s slots ahead
of sl1. Then it holds that len(C2) − len(C1) ≥ τ · s. We call τ the speed coefficient.
Some remarks are in place. Regarding common prefix, we capture a strong notion of common
prefix, cf. [26]. Regarding chain quality, µ, as a function of the ratio of adversarial parties, satisfies
µ(α) ≥ α for protocols of interest. In an ideal setting, µ would be 1−α: in this case, the percentage
of malicious blocks in any sufficiently long chain segment is proportional to the cumulative stake
of a set of (malicious) stakeholders.
It is worth noting that for bitcoin we have µ(α) = (1 − 2α)/(1 − α), and this bound is in fact
tight—see [24], which argues this guarantee on chain quality. The same will hold true for our
protocol construction. As we will show, this will still be sufficient for our incentive mechanism to
work properly.
Finally chain growth concerns the rate at which the chain grows (for honest parties). As in
the case of bitcoin, the longest chain plays a preferred role in our protocol; this provides an easy
guarantee of chain growth.
Security Model. We adopt the model introduced by [24] for analysing security of blockchain
protocols enhanced with an ideal functionality F. We denote by VIEWP,F
Π,A,Z
(λ) the view of party
P after the execution of protocol Π with adversary A, environment Z, security parameter κ and
access to ideal functionality F. Similarly we denote by EXECP,F
Π,A,Z
(λ) the output of Z.
We note that multiple different “functionalities” will be encompassed by F. Contrary to [24],
our analysis is in the “standard model”, and without a random oracle functionality. The first interfaces we incorporate in the ideal functionality used in the protocol are the “diffuse” and “key and
transaction” functionality, denoted FD+KT and described below. Note that the diffuse functionality
is also the mechanism via which we will obtain the synchronization of the protocol.
Diffuse functionality. The diffuse functionality maintains an incoming string for each party Ui
that participates. A party, if activated, is allowed at any moment to fetch the contents of its
incoming string; one may think of this as a mailbox. Additionally, parties can instruct the
functionality to diffuse a message, in which case the message will be appended to each party’s
incoming string. The functionality maintains rounds (slots) and all parties are allowed to
diffuse once in a round. Rounds do not advance unless all parties have diffused a message.
The adversary, when activated, may also interact with the functionality and is allowed to read
all inboxes and all diffuse requests and deliver messages to the inboxes in any order it prefers.
At the end of the round, the functionality will ensure that all inboxes contain all messages
that have been diffused (but not necessarily in the same order they have been requested to be
diffused). The current slot index may be requested at any time by any party. If a stakeholder
does not fetch in a certain slot the messages written to its incoming string, they are flushed.
Key and Transaction functionality. The key registration functionality is initialized with n
users, U1, . . . , Un and their respective stake s1, . . . , sn; given such initialization, the functionality will consult with the adversary and will accept a (possibly empty) sequence of
(Corrupt, U) messages and mark the corresponding users U as corrupt. For the corrupt users
without a public-key registered the functionality will allow the adversary to set their publickeys while for honest users the functionality will sample public/secret-key pairs and record
them based on a digital signature algorithm. Public-keys of corrupt users will be marked as
such. Subsequently, any sequence of the following actions may take place: (i) A user may
request to retrieve its public and secret-key whereupon the functionality will return it to the
user. (ii) The whole directory of public-keys may be required whereupon the functionality
will return it to the requesting user. (iii) A new user may be requested to be created by a
message (Create, U, C) from the environment, in which case the functionality will follow the
same procedure as before: it will consult the adversary regarding the corruption status of U
and will set its public and possibly secret-key depending on the corruption status; moreover
it will store C as the suggested initial state. The functionality will return the public-key
back to the environment upon successful completion of this interaction. (iv) An existing user
may be requested to be corrupted by the adversary via a message (Corrupt, U). A user can
only be corrupted after a delay of D slots; specifically, after a corruption request is registered the secret-key will be released after D slots have passed according to the round counter
maintained in the Diffuse component of the functionality.
Given the above we will assume that the execution of the protocol is with respect to a functionality F that is incorporating the above two functionalities as well as possibly additional functionalities
to be explained below. Note that a corrupted stakeholder U will relinquish its entire state to A;
from this point on, the adversary will be activated in place of the stakeholder U. Beyond any
restrictions imposed by F, the adversary can only corrupt a stakeholder if it is given permission
by the environment Z running the protocol execution. The permission is in the form of a message (Corrupt, U) which is provided to the adversary by the environment. In summary, regarding
activations we have the following.
• At each slot slj , the environment Z is allowed to activate any subset of stakeholders it
wishes. Each one of them will possibly produce messages that are to be transmitted to other
stakeholders.
• The adversary is activated at least as the last entity in each slj , (as well as during all adversarial party activations).
It is easy to see that the model above confers such sweeping power on the adversary that one
cannot establish any significant guarantees on protocols of interest. It is thus important to restrict
the environment suitably (taking into account the details of the protocol) so that we may be able
to argue security. With foresight, the restrictions we will impose on the environment are as follows.
Restrictions imposed on the environment. The environment, which is responsible for activating the honest parties in each round, will be subject to the following constraints regarding the
activation of the honest parties running the protocol.
• In each slot there will be at least one honest activated party.
• There will be a parameter k ∈ Z that will signify the maximum number of slots that an honest
shareholder can be offline. In case an honest stakeholder is spawned after the beginning of
the protocol via (Create, U, C) its initialization chain C provided by the environment should
match an honest parties’ chain which was active in the previous slot.
• In each slot slr, and for each active stakeholder Uj there will be a set Sj (r) of public-keys
and stake pairs of the form (vki
, si) ∈ {0, 1}
∗ × N, for j = 1, . . . , nr where nr is the number
of users introduced up to that slot that will represent who are the active participants in the
view of Uj . Public-keys will be marked as “corrupted” if the corresponding stakeholder has
been corrupted. We will say the adversary is restricted to less than 50% relative stake if it
holds that the total stake of the corrupted keys divided by the total stake P
i
si
is less than
50% in all possible Sj (r). In case the above is violated an event Bad1/2 becomes true for the
given execution.
We note that the offline restriction stated above is very conservative and our protocol can
tolerate much longer offline times depending on the way the course of the execution proceeds;
nevertheless, for the sake of simplicity, we use the above restriction. Finally, we note that in all our
proofs, whenever we say that a property Q holds with high probability over all executions, we will
in fact argue that Q∨Bad1/2 holds with high probability over all executions. This captures the fact
that we exclude environments and adversaries that trigger Bad1/2 with non-negligible probability.
3 Our Protocol: Overview
We first provide a general overview of our protocol design approach. The protocol’s specifics depend
on a number of parameters as follows: (i) k is the number of blocks a certain message should have
“on top of it” in order to become part of the immutable history of the ledger, (ii)  is the advantage
in terms of stake of the honest stakeholders against the adversarial ones; (iii) D is the corruption
delay that is imposed on the adversary, i.e., an honest stakeholder will be corrupted after D slots
when a corrupt message is delivered by the adversary during an execution; (iv) L is the lifetime of
the system, measured in slots; (v) R is the length of an epoch, measured in slots.
We present our protocol description in four stages successively improving the adversarial model
it can withstand. In all stages an “ideal functionality” F
D,F
LS is available to the participants. The
functionality captures the resources that are available to the parties as preconditions for the secure
operation of the protocol (e.g., the genesis block will be specified by F
D,F
LS ).
Stage 1: Static stake; D = L. In the first stage, the trust assumption is static and remains
with the initial set of stakeholders. There is an initial stake distribution which is hardcoded
into the genesis block that includes the public-keys of the stakeholders, {(vki
, si)}
n
i=1. Based on
our restrictions to the environment, honest majority with advantage  is assumed among those
initial stakeholders. Specifically, the environment initially will allow the corruption of a number
of stakeholders whose relative stake represents 1−
2
for some  > 0. The environment allows party
corruption by providing tokens of the form (Corrupt, U) to the adversary; note that due to the
corruption delay imposed in this first stage any further corruptions will be against parties that
have no stake initially and hence the corruption model is akin to “static corruption.” F
D,F
LS will
subsequently sample ρ which will seed a “weighted by stake” stakeholder sampling and in this way
lead to the election of a subset of m keys vki1
, . . . , vkim to form the committee that will possess
honest majority with overwhelming probability in m, (this uses the fact that the relative stake
possessed by malicious parties is 1−
2
; a linear dependency of m to 
−2 will be imposed at this
stage). In more detail, the committee will be selected implicitly by appointing a stakeholder with
probability proportional to its stake to each one of the L slots. Subsequently, stakeholders will
issue blocks following the schedule that is determined by the slot assignment. The longest chain
rule will be applied and it will be possible for the adversary to fork the blockchain views of the
honest parties. Nevertheless, we will prove with a Markov chain argument that the probability
that a fork can be maintained over a sequence of n slots drops exponentially with at least √
n, cf.
Theorem 4.13 against general adversaries. An even more favorable analysis can be made against
covert adversaries, i.e., adversaries that prefer to remain “under the radar” cf. Theorem 4.23.
Stage 2: Dynamic state with a beacon, epoch period of R slots, D = R  L. The central
idea for the extension of the lifetime of the above protocol is to consider the sequential composition
of several invocations of it. We detail a way to do that, under the assumption that a trusted beacon
emits a uniformly random string in regular intervals. More specifically, the beacon, during slots
{j ·R+ 1, . . . ,(j + 1)R}, reveals the j-th random string that seeds the leader election function. The
critical difference compared to the static state protocol is that the stake distribution is allowed to
change and is drawn from the blockchain itself. This means that at a certain slot sl that belongs
to the j-th epoch (with j ≥ 2), the stake distribution that is used is the one reported in the most
recent block with time stamp less than j · R − 2k.
Regarding the evolving stake distribution, transactions will be continuously generated and transferred between stakeholders via the environment and players will incorporate posted transactions in
the blockchain based ledgers that they maintain. In order to accomodate the new accounts that are
being created, the F
D,F
LS functionality enables a new (vk,sk) to be created on demand and assigned
to a new party Ui
. Specifically, the environment can create new parties who will interact with F
D,F
LS
for their public/secret-key in this way treating it as a trusted component that maintains the secret
of their wallet. Note that the adversary can interfere with the creation of a new party, corrupt it,
and supply its own (adversarially created) public-key instead. As before, the environment, may
request transactions between accounts from stakeholders and it can also generate transactions in
collaboration with the adversary on behalf of the corrupted accounts. Recall that our assumption
is that at any slot, in the view of any honest player, the stakeholder distribution satisfies honest
majority with advantage  (note that different honest players might perceive a different stakeholder
distribution in a certain slot). Furthermore, the stake can shift by at most σ statistical distance
over a certain number of slots. The statistical distance here will be measured considering the underlying distribution to be the weighted-by-stake sampler and how it changes over the specified
time interval. The security proof can be seen as an induction in the number of epochs L/R with
the base case supplied by the proof of the static stake protocol. In the end we will argue that in this
setting, a 1−
2 − σ bound in adversarial stake is sufficient for security of a single draw (and observe
that the size of committee, m, now should be selected to overcome also an additive term of size
ln(L/R) given that the lifetime of the systems includes such a number of successive epochs). The
corruption delay remains at D = R which can be selected arbitrarily smaller than L, thus enabling
the adversary to perform adaptive corruptions as long as this is not instantaneous.
Stage 3: Dynamic state without a beacon, epoch period of R slots, R = Θ(k) and delay
D ∈ (R, 2R)  L. In the third stage, we remove the dependency to the beacon, by introducing
a secure multiparty protocol with “guaranteed output delivery” that simulates it. In this way, we
can obtain the long-livedness of the protocol as described in the stage 2 design but only under
the assumption of the stage 1 design, i.e., the mere availability of an initial random string and
an initial stakeholder distribution with honest majority. The core idea is the following: given we
guarantee that an honest majority among elected stakeholders will hold with very high probability,
we can further use this elected set as participants to an instance of a secure multiparty computation
(MPC) protocol. This will require the choice of the length of the epoch to be sufficient so that it
can accommodate a run of the MPC protocol. From a security point of view, the main difference
with the previous case, is that the output of the beacon will become known to the adversary before
it may become known to the honest parties. Nevertheless, we will prove that the honest parties
will also inevitably learn it after a short number of slots. To account for the fact that the adversary
gets this headstart (which it may exploit by performing adaptive corruptions) we increase the wait
time for corruption from R to a suitable value in (R, 2R) that negates this advantage and depends
on the secure MPC design. A feature of this stage from a cryptographic design perspective is the
use of the ledger itself for the simulation of a reliable broadcast that supports the MPC protocol.
Stage 4: Input endorsers, stakeholder delegates, anonymous communication. In the
final stage of our design, we augment the protocol with two new roles for the entities that are
running the protocol and consider the benefits of anonymous communication. Input-endorsers
create a second layer of transaction endorsing prior to block inclusion. This mechanism enables
the protocol to withstand deviations such as selfish mining and enables us to show that honest
behaviour is an approximate Nash equilibrium under reasonable assumptions regarding the costs
of running the protocol. Note that input-endorsers are assigned to slots in the same way that
slot leaders are, and inputs included in blocks are only acceptable if they are endorsed by an
eligible input-endorser. Second, the delegation feature allows stakeholders to transfer committee
participation to selected delegates that assume the responsibility of the stakeholders in running
the protocol (including participation to the MPC and issuance of blocks). Delegation naturally
gives rise to “stake pools” that can act in the same way as mining pools in bitcoin. Finally, we
observe that by including an anonymous communication layer we can remove the corruption delay
requirement that is imposed in our analysis. This is done at the expense of increasing the online
time requirements for the honest parties.4
4 Our Protocol: Static State
4.1 Basic Concepts and Protocol Description
We begin by describing the blockchain protocol πSPoS in the “static stake” setting, where leaders
are assigned to blockchain slots with probability proportional to their (fixed) initial stake which
will be the effective stake distribution throughout the execution. To simplify our presentation, we
abstract this leader selection process, treating it simply as an “ideal functionality” that faithfully
carries out the process of randomly assigning stakeholders to slots. In the following section, we
explain how to instantiate this functionality with a specific secure computation.
We remark that—even with an ideal leader assignment process—analyzing the standard “longest
chain” preference rule in our PoS setting appears to require significant new ideas. The challenge
arises because large collections of slots (epochs, as described above) are assigned to stakeholders at
once; while this has favorable properties from an efficiency (and incentive) perspective, it furnishes
the adversary a novel means of attack. Specifically, an adversary in control of a certain population
of stakeholders can, at the beginning of an epoch, choose when standard “chain update” broadcast
messages are delivered to honest parties with full knowledge of future assignments of slots to
stakeholders. In contrast, adversaries in typical PoW settings are constrained to make such decisions
in an online fashion. We remark that this can have a dramatic effect on the ability of an adversary
to produce alternate chains; see the discussion on “forkable strings” below for detailed discussion.
In the static stake case, we assume that a fixed collection of n stakeholders U1, . . . , Un interact
throughout the protocol. Stakeholder Ui possesses si stake before the protocol starts. For each
stakeholder Ui a verification and signing key pair (vki
,ski) for a prescribed signature scheme is
generated; we assume without loss of generality that the verification keys vk1, . . . are known by all
stakeholders. Before describing the protocol, we establish basic definitions following the notation
of [24].
Definition 4.1 (Genesis Block). The genesis block B0 contains the list of stakeholders identified
by their public-keys, their respective stakes (vk1, s1), . . . ,(vkn, sn) and auxiliary information ρ.
With foresight we note that the auxiliary information ρ will be used to seed the slot leader
election process.
Definition 4.2 (State). A state is a string st ∈ {0, 1}
λ
.
Definition 4.3 (Block). A block B generated at a slot sli ∈ {sl1, . . . , slR} contains the current
state st ∈ {0, 1}
λ
, data d ∈ {0, 1}
∗
, the slot number sli and a signature σ = Signski
(st, d, sli)
computed under ski corresponding to the stakeholder Ui generating the block.
Definition 4.4 (Blockchain). A blockchain (or simply chain) relative to the genesis block B0 is a
sequence of blocks B1, . . . , Bn associated with a strictly increasing sequence of slots for which the
state sti of Bi is equal to H(Bi−1), where H is a prescribed collision-resistant hash function. The
length of a chain len(C) = n is its number of blocks. The block Bn is the head of the chain, denoted
head(C). We treat the empty string ε as a legal chain and by convention set head(ε) = ε.
Let C be a chain of length n and k be any non-negative integer. We denote by C
dk
the chain
resulting from removal of the k rightmost blocks of C. If k ≥ len(C) we define C
dk = ε. We let
C1  C2 indicate that the chain C1 is a prefix of the chain C2.
Definition 4.5 (Epoch). An epoch is a set of R adjacent slots S = {sl1, . . . , slR}.
(The value R is a parameter of the protocol we analyze in this section.)
Definition 4.6 (Adversarial Stake Ratio). Let UA be the set of stakeholders controlled by an
adversary A. Then the adversarial stake ratio is defined as
α =
P
j∈UA
sj
Pn
i=1 si
,
where n is the total number of stakeholders and si is stakeholder Ui’s stake.
Slot Leader Selection. In the protocol described in this section, for each 0 < j ≤ R, a slot
leader Ej is determined who has the (sole) right to generate a block at slj . Specifically, for each
slot a stakeholder Ui
is selected as the slot leader with probability pi proportional to its stake
registered in the genesis block B0; these assignments are independent between slots. In this static
stake case, the genesis block as well as the procedure for selecting slot leaders are determined by
an ideal functionality F
D,F
LS , defined in Figure 1. This functionality is parameterized by the list
{(vk1, s1), . . . ,(vkn, sn)} assigning to each stakeholder its respective stake, a distribution D that
provides auxiliary information ρ and a leader selection function F defined below.
Definition 4.7 (Leader Selection Process). A leader selection process with respect to stakeholder
distribution S = {(vk1, s1), . . . ,(vkn, sn)}, (D, F) is a pair consisting of a distribution and a deterministic function such that, when ρ ← D it holds that for all slj ∈ {sl1, . . . , slR}, F(S, ρ, slj )
outputs Ui ∈ {U1, . . . , Un} with probability
pi =
si
Pn
k=1 sk
where si is the stake held by stakeholder Ui (we call this “weighing by stake”); furthermore the
family of random variables {F(S, ρ, slj )}
R
j=1 are independent.
We note that sampling proportional to stake can be implemented in a straightforward manner.
For instance, a simple process operates as follows. Let ˜pi = si/
Pn
j=i
sj . For each i = 1, . . . , n − 1,
provided that no stakeholder has yet been selected, the process flips a ˜pi-biased coin; if the result
of the coin is 1, the party Ui
is selected for the slot and the process is complete. (Note that ˜pn = 1,
so the process is certain to complete with a unique leader.) When we implement this process as
a function F(·), sufficient randomness must be allocated to simulate the biased coin flips. If we
implement the above with λ precision for each individual coin flip, then selecting a stakeholder will
require ndlog λe random bits in total. Note that using a pseudorandom number generator (PRG)
one may use a shorter “seed” string and then stretch it using the PRG to the appropriate length.
A Protocol in the F
D,F
LS [mode]-hybrid model. We start by describing a simple PoS based
blockchain protocol considering static stake in the F
D,F
LS [SIG]-hybrid model, i.e., where the genesis
block B0 (and consequently the slot leaders) are determined by the ideal functionality F
D,F
LS [SIG].
F
D,F
LS [SIG] provides the stakeholders with a genesis block containing a stake distribution indexed by
signature verification keys generated by a EUF-CMA signature scheme, while F
D,F
LS [FDSIG] obtains
such keys from a signature ideal functionality FDSIG. This subtle difference comes into play when
describing an ideal version of πSPoS used in an intermediate hybrid argument of the security proof,
which will be discussed in Section 4.2. The stakeholders U1, . . . , Un interact among themselves and
with F
D,F
LS through Protocol πSPoS described in Figure 2.
The protocol relies on a maxvalidS(C, C) function that chooses a chain given the current chain
C and a set of valid chains C that are available in the network. In the static case we analyze the
simple “longest chain” rule. (In the dynamic case the rule is parameterized by a common chain
length; see Section 5.)
Function maxvalid(C, C): Returns the longest chain from C ∪ {C}. Ties are broken in
favor of C, if it has maximum length, or arbitrarily otherwise.
4.2 Security Analysis of an Ideal Protocol
As a first step of the security analysis of πSPoS, we will introduce an idealized protocol πiSPoS and
present an intermediate hybrid argument that shows that it is computationally indistinguishable
from πSPoS. Instead of relying on F
D,F
LS [SIG] and an EUF-CMA signature scheme, πiSPoS operates
with an ideal signature scheme. To that end, πiSPoS interacts with F
D,F
LS [FDSIG] for obtaining signing
and verification keys for the ideal signature scheme employed in the protocol. In the next sessions,
we will prove that πiSPoS is secure through a series of combinatorial arguments. The reason we
first present this hybrid is that we intend to insulate these combinatorial arguments from the
specific details of the underlying signature schemes used to instantiate πSPoS and the biases that
these schemes might introduce in the distributions of πSPoS, concentrating instead on idealized
executions where signature schemes are perfectly realized, which reflects the true nature of our
protocol.
First, in Figure 3, we present Functionality FDSIG as defined in [14], where it is also shown that
EUF-CMA signature schemes realize FDSIG. Notice that this fact will be used to show that our
idealized protocol can actually be realized based on practical digital signature schemes such DSA
and ECDSA) and ultimately that πiSPoS is indistinguishable from πSPoS.
The idealized protocol πiSPoS is run by the stakeholders interacting with F
D,F
LS [FDSIG] and FDSIG.
Basically, πiSPoS behaves exactly as πSPoS except for calls to Vrfvk(σ) and Signsk(m). Namely, instead
of locally computing Signski
(m), Ui sends (Sign, sid, m) to FDSIG, receiving (Signature, sid, m, σ)
and outputting σ as the signature. Moreover, instead locally computing Vrfvk0(σ, m), Ui sends
(Verify, sidi
, m, σ, v0
) to FDSIG (where v
0
corresponds to verification key vk0
), outputting the value
f received in message (Verified, sidi
, m, f). Protocol πiSPoS is described in Figure 4. This idealized
description will be further developed when arguing about the dynamic stake case, where additional
building blocks must be considered in the idealized protocol.
The following proposition is an immediate corollary of the results in [14] showing that EUF-CMA
signature schemes realize FDSIG.
Proposition 4.8. For each PPT A, Z it holds that there is a PPT S so that EXECP,F
D,F
LS [SIG]
πSPoS,A,Z
(λ)
and EXECP,F
D,F
LS [FDSIG]
πiSPoS,S,Z
(λ) are computationally indistinguishable.
In light of the above proposition in the remaining of the analysis we will focus on the properties
of the protocol πiSPoS (note that this implication does not apply to any5 possible property one
might consider in an execution for πiSPoS; nevertheless the properties we will prove for πiSPoS are all
verifiable by the environment Z and as a result they can be inherited by πSPoS due to proposition
).
4.3 Forkable Strings
In our security arguments we routinely use elements of {0, 1}
n
to indicate which slots—among
a particular window of slots of length n—have been assigned to adversarial stakeholders. When
strings have this interpretation we refer to them as characteristic strings.
Definition 4.9 (Characteristic String). Fix an execution with genesis block B0, adversary A, and
environment Z. Let S = {sli+1, . . . , sli+n} denote a sequence of slots of length |S| = n. The
characteristic string w ∈ {0, 1}
n of S is defined so that wk = 1 if and only if the adversary controls
the slot leader of slot sli+k. For such a characteristic string w ∈ {0, 1}
∗ we say that the index i is
adversarial if wi = 1 and honest otherwise.
We start with some intuition on our approach to analyze the protocol. Let w ∈ {0, 1}
n be a
characteristic string for a sequence of slots S. Consider two observers that (i.) go offline immediately
prior to the commencement of S, (ii.) have the same view C0 of the current chain prior to the
commencement of S, and (iii.) come back online at the last slot of S and request an update of their
chain. A fundamental concern in our analysis is the possibility that such observers can be presented
with a “diverging” view over the sequence S: specifically, the possibility that the adversary can
force the two observers to adopt two different chains C1, C2 whose common prefix is C0.
We observe that not all characteristic strings permit this. For instance the (entirely honest)
string 0n
ensures that the two observers will adopt the same chain C which will consist of n new
blocks on top of the common prefix C0. On the other hand, other strings do not guarantee such
common extension of C0; in the case of 1n
, it is possible for the adversary to produce two completely
different histories during the sequence of slots S and thus furnish to the two observers two distinct
chains C1, C2 that only share the common prefix C0. In the remainder of this section, we establish
that strings that permit such “forkings” are quite rare—indeed, we show that they have density
2
−Ω(√
n)
so long as the fraction of adversarial slots is 1/2 − .
To reason about such “forkings” of a characteristic string w ∈ {0, 1}
n
, we define below a formal
notion of “fork” that captures the relationship between the chains broadcast by honest slot leaders
during an execution of the protocol πiSPoS. In preparation for the definition, we recall that honest
players always choose to extend a maximum length chain among those available to the player on
the network. Furthermore, if such a maximal chain C includes a block B previously broadcast by
an honest player, the prefix of C prior to B must entirely agree with the chain (terminating at B)
broadcast by this previous honest player. This “confluence” property follows immediately from the
fact that the state of any honest block effectively commits to a unique chain beginning at the genesis
block. To conclude, any chain C broadcast by an honest player must begin with a chain produced
by a previously honest player (or, alternatively, the genesis block), continue with a possibly empty
sequence of adversarial blocks and, finally, terminate with an honest block. It follows that the
chains broadcast by honest players form a natural directed tree. The fact that honest players
reliably broadcast their chains and always build on the longest available chain introduces a second
important property of this tree: the “depths” of the various honest blocks added by honest players
during the protocol must all be distinct.
Of course, the actual chains induced by an execution of πiSPoS are comprised of blocks containing
a variety of data that are immaterial for reasoning about forking. For this reason the formal notion
of fork below merely reflects the directed tree formed by the relevant chains and the identities of
the players—expressed as indices in the string w—responsible for generating the blocks in these
chains.
Forks and forkable strings. We define, below, the basic combinatorial structures we use to
reason about the possible views observed by honest players during a protocol execution with this
characteristic string.
Definition 4.10 (Fork). Let w ∈ {0, 1}
n and let H = {i | wi = 0} denote the set of honest indices.
A fork for the string w is a directed, rooted tree F = (V, E) with a labeling ` : V → {0, 1, . . . , n} so
that
• each edge of F is directed away from the root;
• the root r ∈ V is given the label `(r) = 0;
• the labels along any directed path in the tree are strictly increasing;
• each honest index i ∈ H is the label of exactly one vertex of F;
• the function d : H → {1, . . . , n}, defined so that d(i) is the depth in F of the unique vertex v
for which `(v) = i, is strictly increasing. (Specifically, if i, j ∈ H and i < j, then d(i) < d(j).)
Figure 5: A fork F for the string w = 010100110; vertices appear with their labels and honest
vertices are highlighted with double borders. Note that the depths of the (honest) vertices associated
with the honest indices of w are strictly increasing. Two tines are distinguished in the figure: one,
labeled tˆ, terminates at the vertex labeled 9 and is the longest tine in the fork; a second tine t
terminates at the vertex labeled 3. The quantity gap(t) indicates the difference in length between t
and tˆ; in this case gap(t) = 4. The quantity reserve(t) = |{i | `(v) < i ≤ |w| and wi = 1}| indicates
the number of adversarial indices appearing after the label of the last honest vertex v of the tine;
in this case reserve(t) = 3. As each leaf of F is honest, F is closed.
As a matter of notation, we write F ` w to indicate that F is a fork for the string w. We say that
a fork is trivial if it contains a single vertex, the root.
Definition 4.11 (Tines, depth, and height; the ∼ relation). A path in a fork F originating at the
root is called a tine. For a tine t we let length(t) denote its length, equal to the number of edges
on the path. For a vertex v, we let depth(v) denote the length of the (unique) tine terminating at
v. The height of a fork (as usual for a tree) is defined to be the length of the longest tine.
We overload the notation `() so that it applies to tines, by defining `(t) , `(v), where v is the
terminal vertex on the tine t. For two tines t1 and t2 of a fork F, we write t1 ∼ t2 if they share an
edge. Note that ∼ is an equivalence relation on the set of nontrivial tines; on the other hand, if t
denotes the “empty” tine consisting solely of the root vertex then t 6∼ t for any tine t.
If a vertex v of a fork is labeled with an adversarial index (i.e., w`(v) = 1) we say that the vertex
is adversarial; otherwise, we say that the vertex is honest. For convenience, we declare the root
vertex to be honest. We extend this terminology to tines: a tine is honest if it terminates with an
honest vertex and adversarial otherwise. By this convention the empty tine t is honest.
See Figure 5 for an example, which also demonstrates some of the quantities defined above and
in the remainder of this section. The fork shown in the figure reflects an execution in which (i.)
the honest player associated with the first slot builds directly on the genesis block (as it must),
(ii.) the honest player associated with the third slot is shown a chain of length 1 produced by the
adversarial player of slot 2 (in addition to the honestly generated chain of step (i.)), which it elects
to extend, (iii.) the honest player associated with slot 5 is shown a chain of length 2 building on
the chain of step (i.) augmented with a further adversarial block produced by the player of slot 4,
etc.
Definition 4.12. We say that a fork is flat if it has two tines t1 6∼ t2 of length equal to the height
of the fork. A string w ∈ {0, 1}
∗
is said to be forkable if there is a flat fork F ` w.
Note that in order for an execution of πiSPoS to yield two entirely disjoint chains of maximum
length, the characteristic string associated with the execution must be forkable. Our goal is to
establish the following upper bound on the number of forkable strings.
Theorem 4.13. Let  ∈ (0, 1) and let w be a string drawn from {0, 1}
n
by independently assigning
each wi = 1 with probability (1 − )/2. Then Pr[w is forkable] = 2−Ω(√
n)
.
Note that in subsequent work, Russell et al. [37] improved this bound to 2−Ω(n)
.
Structural features of forks: closed forks, prefixes, reach, and margin. We begin by
defining a natural notion of inclusion for two forks:
Definition 4.14 (Fork prefixes). If w is a prefix of the string w
0 ∈ {0, 1}
∗
, F ` w, and F
0 ` w
0
,
we say that F is a prefix of F
0
, written F v F
0
, if F is a consistently-labeled subgraph of F
0
.
Specifically, every vertex and edge of F appears in F
0 and, furthermore, the labels given to any
vertex appearing in both F and F
0 are identical.
If F v F
0
, each tine of F appears as the prefix of a tine in F
0
. In particular, the labels appearing
on any tine terminating at a common vertex are identical and, moreover, the depth of any honest
vertex appearing in both F and F
0
is identical.
In many cases, it is convenient to work with forks that do not “commit” anything beyond final
honest indices.
Definition 4.15 (Closed forks). A fork is closed if each leaf is honest. By convention the trivial
fork, consisting solely of a root vertex, is closed.
Note that a closed fork has a unique longest tine (as all maximal tines terminate with an honest
vertex, and these must have distinct depths). Note, additionally, that if ˇw is a prefix of w and
F ` w, then there is a unique closed fork Fˇ ` wˇ for which Fˇ v F. In particular, taking ˇw = w, we
note that for any fork F ` w, there is a unique closed fork F ` w for which F v F; in this case we
say that F is the closure of F.
Definition 4.16 (Gap, reserve and reach). Let F ` w be a closed fork and let tˆ denote the (unique)
tine of maximum length in F. We define the gap of a tine t, denoted gap(t), to be the difference in
length between tˆ and t; thus
gap(t) = length(tˆ) − length(t).
We define the reserve of a tine t to be the number of adversarial indices appearing in w after the
last index in t; specifically, if t is given by the path (r, v1, . . . , vk), where r is the root of F, we define
reserve(t) = |{i | wi = 1 and i > `(vk)}| .
We remark that this quantity depends both on F and the specific string w associated with F. Finally,
for a tine t we define
reach(t) = reserve(t) − gap(t).
Definition 4.17 (Margin). For a closed fork F ` w we define ρ(F) to be the maximum reach taken
over all tines in F:
ρ(F) = max
t
reach(t).
Likewise, we define the margin of F, denoted µ(F), to be the “penultimate” reach taken over edgedisjoint tines of F: specifically,
margin(F) = µ(F) = max
t16∼t2

min{reach(t1),reach(t2)}

.
We remark that the maxima above can always obtained by honest tines. Specifically, if t is an
adversarial tine of a fork F ` w, reach(t) ≤ reach(t), where t is the longest honest prefix of t.
As ∼ is an equivalence relation on the nonempty tines, it follows that there is always a pair of
(edge-disjoint) tines t1 and t2 achieving the maximum in the defining equation (1) which satisfy
reach(t1) = ρ(F) ≥ reach(t2) = µ(F).
The relevance of margin to the notion of forkability is reflected in the following proposition.
Proposition 4.18. A string w is forkable if and only if there is a closed fork F ` w for which
margin(F) ≥ 0.
Proof. If w has no honest indices, then the trivial fork consisting of a single root node is flat, closed,
and has non-negative margin; thus the two conditions are equivalent. Consider a forkable string w
with at least one honest index and let ˆi denote the largest honest index of w. Let F be a flat fork
for w and let F ` w be the closure of F (obtained from F by removing any adversarial vertices from
the ends of the tines of F). Note that the tine tˆ containing ˆi is the longest tine in F, as this is the
largest honest index of w. On the other hand, F is flat, in which case there are two edge-disjoint
tines t1 and t2 with length at least that of tˆ. The prefixes of these two tines in F must clearly have
reserve no less than gap (and hence non-negative reach); thus margin(F) ≥ 0 as desired.
On the other hand, suppose w has a closed fork with margin(F) ≥ 0, in which case there are
two edge-disjoint tines of F, t1 and t2, for which reach(ti) ≥ 0. Then we can produce a flat fork by
simply adding to each ti a path of gap(ti) vertices labeled with the subsequent adversarial indices
promised by the definition of reserve().
Note that this overloads the notation ρ(·) and µ(·) so that they apply to both forks and strings,
but the setting will be clear from context. We remark that the definitions do not guarantee a priori
that ρ(w) and µ(w) can be achieved by the same fork, though this will be established in the lemma
below. In any case, it is clear that ρ(w) ≥ 0 and ρ(w) ≥ µ(w) for all strings w; furthermore, by
Proposition 4.18 a string w is forkable if and only if µ(w) ≥ 0. We refer to µ(w) as the margin of
the string w.
In preparation for the proof of Theorem 4.13, we establish a recursive description for these
quantities
In light of the properties (3) above, the random variables Rt are quite well-behaved when
positive—in particular, considering the distribution placed on each wi
, they simply follow the
familiar biased random walk of Figure 6. Likewise, considering the properties (4), the random
variables Mt follow a biased random walk when negative. The remainder of the proof combines
these probability laws with (5) and the fact that Mt() ≤ Rt() to establish that Mn < 0 with high
probability.
We recall two basic facts about the standard biased walk associated with the Markov chain of
Figure 6. Let Zi ∈ {±1} (for i = 1, 2, . . .) denote a family of independent random variables for
which Pr[Zi = 1] = (1 − )/2. Then the biased walk given by the variables Yt =
Pt
i Zi has the
following properties.
Constant escape probability; gambler’s ruin. With constant probability, depending only on
, Yt 6= 1 for all t > 0. In general, for each k > 0,
Pr[∃t, Yt = k] = α
k
, (6)
for a constant α < 1 depending only on . (In fact, the constant α is (1 − )/(1 + ); see, e.g.,
[25, Chapter 12] for a complete development.)
Concentration (the Chernoff bound). Consider T steps of the biased walk beginning at state
0; then the resulting value is tightly concentrated around −T. Specifically, E[YT ] = −T and
Partitioning the string w, we write w = w
(1)
· · · w
(
√
n) where w
(t) = w1+at−1
. . . wat and at = dt
√
ne,
for t = 0, 1, . . .. Let R(0) = 0 and R(t) = Rat
; similarly define M(0) = 0 and M(t) = Mat
. Fix δ  
to be a small constant.
We define three events based on the random variables R(t) and M(t)
:
Hot We let Hott denote the event that R(t) ≥ δ
√
n and M(t) ≥ −δ
√
n.
Volatile We let Volt denote the event that −δ
√
n ≤ M(t) ≤ R(t) < δ√
n.
Cold We let Coldt denote the event that M(t) < −δ
√
n.
Note that for each t, exactly one of these events occurs—they partition the probability space. Then
we will establish that
Note that the event Vol0 occurs by definition. Assuming these inequalities, we observe that the
system is very likely to eventually become cold, and stay that way. In this case, Cold√
n
occurs,
M◦
n < δ√
n < 0, and w is not forkable. Specifically, note that the probability that the system
ever transitions from volatile to hot is no more than 2−Ω(√
n)
(as transition from Vol to Hot is
bounded above by 2−Ω(√
n)
, and there are no more than √
n possible transition opportunities).
Note, also, that while the system is volatile, it transitions to cold with constant probability during
each period. In particular, the probability that the system is volatile for the entire process is no
more that 2−Ω(√
n)
. Finally, note that the probability that the system ever transitions out of the
cold state is no more than 2−Ω(√
n)
(again, there are at most √
n possible times when this could
happen, and any individual transition occurs with probability 2−Ω(√
n)
). It follows that the system
is cold at the end of the process with probability 1 − 2
−Ω(√
n)
.
It remains to establish the three inequalities (8), (9), and (10).
Inequality (8): This follows directly from (3) and (6). Specifically, in light of (4) the random
variables Mi follow the probability law of the simple biased walk when they are negative.
Conditioned on M(t) = Mat < −δ
√
n, the probability that any future Ms ever climbs to the
value −1 is no more than α
−δ
√
n = 2−Ω(n)
, as desired. (Here α < 1 is a fixed constant that
depends only on .)
Inequality (9): This follows from (3), (5), (6), and (7). Specifically, conditioned on Volt
, R(t) ≤
δ
√
n. Recall from (3) that the random variables Ri follow the probability law of the simple
biased walk when they are positive. Let D be the event that Ri > 0 for all at ≤ i < at+2δ
√
n.
According to (7), then, where we take T = 2δ
√
n, Pr[D] ≤ 2
−Ω(√
n)
. With near certainty, then,
the random variables Ri visit the value 0 during this period. Observe that if Ri = 0 then,
by (5), Mi+1 ≤ −1 with constant probability and (conditioned on this), by (6), with constant
probability the subsequent random variables Mj do not return to the value 0. Additionally,
in light of (7), the probability that there is a sequence wi
. . . wj of length at least 2(δ/)
√
n
for which
is no more than (√
n)
22
−Ω(√
n)
. It follows that with constant probability, the walk (of Ri)
hits 0, as described above, and then Mi terminates at a value less than −δ
√
n.
Inequality (10): This follows from (3), (5), (6), and (7). Specifically, conditioned on Volt
, R(t) ≤
δ
√
n. Recall from (3) that the random variables Ri follow the probability law of the simple
biased walk when they are positive. Let D be the event that Ri > 0 for all at ≤ i < at+2δ
√
n.
According to (7), then, where we take T = 2δ
√
n, Pr[D] ≤ 2
−Ω(√
n)
. With near certainty,
then, the random variables Ri visit the value 0 during this period. Conditioned on D, in order
for Rat+1 ≥ δ
√
n there must be a sequence of these random variables 0 = Ri
, Ri+1, . . . , Rj =
bδ
√
nc so that none of these take the value 0 except the first. (Such a sequence arises by
taking i to be the last time the variables Rat
, . . . visit 0 and j the first subsequent time
that the sequence is larger than δ
√
n.) In light of (6), the probability of such a subsequence
appearing at a particular value for i is no more than α
−δ
√
n
. It follows that the probability
that Rat+1 ≥ δ
√
n is less than √
nα−δ
√
n = 2−Ω(√
n)
, as desired.
Exact probabilities of forkability for explicit values of n. In order to gain further insight
regarding the density of forkable strings, we exactly computed the probability that a string w drawn
from the binomial distribution with parameter p ∈ {.40, .41, . . . , .50} is forkable for several different
lengths. These results are presented in Figure 8.
4.3.1 Covert adversaries, covert forks, and covertly forkable strings
The general notion of fork defined in Definition 4.10 above reflects the possibility that adversarial
slot leaders may broadcast multiple blocks for a single slot; such adversaries may simultaneously
extend many different chains. While this provides the adversary significant opportunities to interfere with the protocol, it leaves a suspicious “audit trail”—multiple signed blocks for the same
slot—which conspicuously deviates from the protocol.
This motivates our consideration of a restricted class of covert adversaries, who broadcast no
more than one block per slot. Such an adversary may still deviate from the protocol by extending short chains, but does not produce such suspicious evidence and hence its strategy is more
“deniable”: it can blame network delays for its actions.6
Such an adversary yields a restricted notion of fork, defined below:
Figure 8: Graphs of the probability that a string drawn from the binomial distribution is forkable.
Graphs for string lengths n = 500, 1000, 1500, 2000 are shown with parameters .40, .41, . . . , .49, .50.
Definition 4.20. Let F ` w be a fork for a string w ∈ {0, 1}
∗
. We say that F is covert if the
labeling ` : V → {0, 1, . . . , } is injective. In particular, no adversarial index is labeled by more than
one node.
As in the general case, we define a notion of forkable string for such adversaries.
Definition 4.21. We say that a string w is covertly forkable if there is a flat covert fork F ` w.
Covert adversaries and forks have much simpler structure than general adversaries. In particular, a string is covertly forkable if and only if a majority of its indices are adversarial. This provides
an analogue of Proposition 4.18 for covertly forkable strings.
Proposition 4.22. A string w ∈ {0, 1}
n
is covertly forkable if and only if wt(w) ≥ n/2.
Proof. Let w be a covertly forkable string and F ` w a flat covert fork. As F is flat, there are
two edge disjoint tines, t1 and t2, with length equal to height(F) and it follows that the number
of vertices in F is at least 2 · height(F) + 1. In this covert case the labeling function is injective,
and it follows that n ≥ 2 · height(F). (Recall that the root vertex is labeled by 0, which is not an
index into w.) On the other hand, the height of F is at least the number of honest indices of w.
We conclude that the length of w is at least twice the number of honest indices, as desired.
If wt(w) ≥ n/2, we can produce a flat covert fork F ` w by placing all honest indices on a
common tine t1 and selecting length(t1) adversarial indices to form an edge-disjoint second tine
t2.
As the structure of covertly forkable strings is so simple, an analogue of Theorem 4.13 for the
density of covertly forkable strings follows directly from standard large deviation bounds.
Exact probabilities of covert forkability for explicit values of n. For comparison with
the general case, we computed the probability that a string drawn from the binomial distribution
is covertly forkable. These results are presented in Figure 9. (Note that these probabilities are
simply appropriate evaluations of the cumulative density function of the binomial distribution.)
Analogous results for the general case appeared in Figure 8.
Figure 9: Graphs of the probability that a string drawn from the binomial distribution is
covertly forkable. Graphs for string lengths n = 500, 1000, 1500, 2000 are shown with parameters
.40, .41, . . . , .49, .50.
4.4 Common Prefix
Recall that the chains constructed by honest players during an execution of πiSPoS correspond to
tines of a fork, as defined and studied in the previous sections. The random assignment of slots to
stakeholders given by F
D,F
LS guarantees that the coordinates of the associated characteristic string w
follow the binomial distribution with probability equal to the adversarial stake. Thus Theorem 4.13
establishes that no execution of the protocol πiSPoS can induce two tines (chains) of maximal length
with no common prefix.
In the context of πiSPoS, however, we wish to establish a much stronger common prefix property:
any pair of chains which could, in principle, be presented by the adversary to an honest party must
have a “recent” common prefix, in the sense that removing a small number of blocks from the
shorter chain results in a prefix of the longer chain.
To formally articulate and prove this property, we introduce some further definitions regarding
tines and forks. We borrow the “truncation operator”, described earlier in the paper for chains:
for a tine t we let t
dk denote the tine obtained by removing the last k edges; if length(t) ≤ k, we
define t
dk
to consist solely of the root.
Definition 4.24 (Viability). Let F ` w be a fork for a string w ∈ {0, 1}
n and let t be a tine of F.
We say that t is viable if, for all honest indices h ≤ `(t), we have
d(h) ≤ length(t).
(Recall that `(t) is the label of the terminal vertex of t.)
If t is viable, an external (honest) observer witnessing the execution at time `(t)—if provided
the tine t along with all honest tines generated up to time `(t)—could conceivably select t via the
maxvalid() rule. Observe that any honest tine is viable: by definition, the depth of the terminal
vertex of an honest tine exceeds that of all prior honest vertices.
Definition 4.25 (Divergence). Let F be a fork for a string w ∈ {0, 1}
∗
. For two viable tines t1
and t2 of F, define their divergence to be the quantity
div(t1, t2) = min
i
(length(ti) − length(t1 ∩ t2)),
where t1∩t2 denotes the common prefix of t1 and t2. We overload this notation by defining divergence
for F as the maximum over all pairs of viable tines:
div(F) = max
t1, t2 viable
tines of F
div(t1, t2).
Finally, define the divergence of w to be the maximum such divergence over all all possible forks
for w:
div(w) = max
F`w
div(F).
Observe that if div(t1, t2) ≤ k and, say, length(t1) ≤ length(t2), the tine t
dk
1
is a prefix of t2.
We first establish that a string with large divergence must have a large forkable substring. We
then apply this in Theorem 4.27 below to conclude that characteristic strings arising from πiSPoS
are unlikely to have large divergence and, hence, possess the common prefix property.
Theorem 4.26. Let w ∈ {0, 1}
∗
. Then there is forkable substring wˇ of w with |wˇ| ≥ div(w).
Proof. Consider a fork F ` w and a pair of viable tines (t1, t2) for which
div(t1, t2) = div(w). (11)
For simplicity, we assume the tines have been labeled so that `(t1) < `(t2) and further that
|`(t2) − `(t1)| is minimum among all pairs of tines for which (11) holds. (12)
We begin by identifying the substring ˇw; the remainder of the proof is devoted to constructing
a flat fork for ˇw to establish forkability. Let y denote the last vertex on the tine t1 ∩ t2, as in the
diagram below, and let α , `(y) = `(t1 ∩ t2).
Let β denote the smallest honest index of w for which β ≥ `(t2), with the convention that if there
is no such index we define β = n + 1. Observe that, in any case, `(t1) < `(t2) and hence that
β − 1 ≥ `(t1). These indices, α and β, distinguish the substring ˇw = wα+1 . . . wβ−1, which will be
the subject of the remainder of the proof. As the function `(·) is strictly increasing along any tine,
observe that
|wˇ| = β − α − 1 ≥ `(t1) − `(y) ≥ length(t1) − length(t1 ∩ t2)
≥ min(length(t1), length(t2)) − length(t1 ∩ t2) = div(w),
so ˇw has the desired length and it suffices to establish that it is forkable.
We briefly summarize the proof before presenting the details. We begin by establishing several
structural properties of the tines t1 and t2 that follow from the assumptions (11) and (12) above.
To establish that ˇw is forkable we then extract from F a flat fork (for ˇw) in two steps: (i.) the fork
F is subjected to some minor restructuring to ensure that all “long” tines pass through y; (ii.) a
flat fork is constructed by treating the vertex y as the root of a portion of the subtree of F labeled
with indices of ˇw. At the conclusion of the construction, segments of the two tines t1 and t2 will
yield the required “long, disjoint” tines satisfying the definition of forkable.
We observe, first of all, that the vertex y cannot be adversarial: otherwise it is easy to construct
an alternative fork F˜ ` w and a pair of tines in F˜ that achieve larger divergence. Specifically,
construct F˜ from F by adding a new (adversarial) vertex ˜y to F for which `(˜y) = `(y), adding an
edge to ˜y from the vertex preceding y, and replacing the edge of t1 following y with one from ˜y;
then the other relevant properties of the fork are maintained, but the divergence of the resulting
tines has increased by one. (See the diagram below.)
A similar argument implies that the fork F0 ` w1 . . . wα obtained by including only those vertices
of F with labels less than or equal to α = `(y) has a unique vertex of depth depth(y) (namely, y
itself). In the presence of another vertex ˜y (of F0) with depth depth(y), “redirecting” t1 through
y˜ (as in the argument above) would likewise result in a fork with larger divergence. Note that `(·)
would indeed be increasing along this new tine (resulting from redirecting t1) because `(˜y) ≤ `(y)
according to the definition of F0. As α is the last index of the string, this additionally implies that
F0 has no vertices of depth exceeding depth(y).
We remark that the minimality assumption (12) implies that any honest index h for which
h < β has depth no more than min(length(t1), length(t2)): specifically,
h < β =⇒ d(h) ≤ min(length(t1), length(t2)). (13)
To see this, consider an honest index h < β and a tine th for which `(th) = h. Recall that t1 and
t2 are viable; as h < `(t2) it follows immediately that d(h) ≤ length(t2). Similarly, if h ≤ `(t1)
then d(h) ≤ length(t1), so it remains to settle the case when `(t1) < h < `(t2): in particular, in
this regime we wish to likewise guarantee that d(h) ≤ length(t1). For the sake of contradiction,
assume that length(th) = d(h) > length(t1). Considering the tine th, we separately investigate
two cases depending on whether th shares an edge with t1 after the vertex y. If, indeed, th and t1
share an edge after the vertex y then th and t2 do not share such an edge, and we observe that
div(th, t2) ≥ div(t1, t2) while |`(t2) − h| < |`(t2) − `(t1)| which contradicts (12). If, on the other
hand, th shares no edge with t1 after y, we similarly observe that div(t1, th) ≥ div(t1, t2) while
|th − `(t1)| < |`(t2) − `(t1)|, which contradicts (12).
In light of the remarks above, we observe that the fork F may be “pinched” at y to yield an
essentially identical fork F
ByC ` w with the exception that all tines of length exceeding depth(y)
pass through the vertex y. Specifically, the fork F
ByC ` w is defined to be the graph obtained
from F by changing every edge of F directed towards a vertex of depth depth(y) + 1 so that it
originates from y. To see that the resulting tree is a well-defined fork, it suffices to check that `(·)
is still increasing along all tines of F
ByC. For this purpose, consider the effect of this pinching on
an individual tine t terminating at a particular vertex v—it is replaced with a tine t
ByC defined so
that:
• If length(t) ≤ depth(y), the tine t is unchanged: t
ByC = t.
• Otherwise, length(t) > depth(y) and t has a vertex z of depth depth(y) + 1; note that
`(z) > `(y) because F0 contains no vertices of depth exceeding depth(y). Then t
ByC is
defined to be the path given by the tine terminating at y, a (new) edge from y to z, and the
suffix of t beginning at z. (As `(z) > `(y) this has the increasing label property.)
Thus the tree F
ByC is a legal fork on the same vertex set; note that depths of vertices in F and
F
ByC are identical.
By excising the tree rooted at y from this pinched fork F
ByC we may extract a fork for the
string wα+1 . . . wn. Specifically, consider the induced subgraph F
yC of F
ByC given by the vertices
{y} ∪ {z | depth(z) > depth(y)}. By treating y as a root vertex and suitably defining the labels
`
yC of F
yC so that `
yC(z) = `(z) − `(y), this subgraph has the defining properties of a fork for
wα+1 . . . wn. In particular, considering that α is honest it follows that each honest index h > α has
depth d(h) > length(y) and hence labels a vertex in F
yC. For a tine t of F
ByC, we let t
yC denote
the suffix of this tine beginning at y, which forms a tine in F
yC. (If length(t) ≤ depth(y), we define
t
yC to consist solely of the vertex y.) Note that t
yC
1
and t
yC
2
share no edges in the fork F
yC.
It is immediate that Fˇ ` wˇ. To conclude the proof, we show that Fˇ is flat. For this purpose, we
consider the tines t
yC
1
and t
yC
2
. As mentioned above, they share no edges in F
yC, and hence the
prefixes tˇ1 and tˇ2 (of t
yC
1
and t
yC
2
) appearing in Fˇ share no edges. We wish to see that these prefixes
have maximum length in Fˇ, in which case Fˇ is flat, as desired. This is immediate for the tine tˇ1
because all labels of t
yC
1
are drawn from ˇw and, considering (13), its depth is at least that of all
relevant honest vertices. As for tˇ2, observe that if `(t2) is not honest then β > `(t2) so that, as with
tˇ1, the tine tˇ2 is labeled by ˇw so that the same argument, relying on (13), ensures that tˇ2 has length
at least that of all relevant honest vertices. If `(t2) is honest, β = `(t2), and the terminal vertex of
t
yC
2 does not appear in Fˇ (as it does not index ˇw). In this case, however, length(t
yC
2
) > d(h) for
any honest index of ˇw, and it follows that length(tˇ2) = length(t
yC
2
) − 1 is at least the depth of any
honest index of ˇw, as desired.
Theorem 4.27. Let k, R ∈ N and  ∈ (0, 1). The probability that the πiSPoS protocol, when executed
with a (1 − )/2 fraction of adversarial stake, violates the common prefix property with parameter
k throughout an epoch of R slots is no more than exp(−Ω(√
k) + ln R); the constant hidden by the
Ω() notation depends only on .
Observe that an execution of πiSPoS violates the common prefix property with parameters
k, R precisely when the fork F induced by this execution has div(F) ≥ k. Thus we wish to show
that the probability that div(w) ≥ k is no more than exp(−Ω(√
k) + log R). Let Bad denote the
event that div(w) ≥ k.
It follows from Theorem 4.26 that if div(w) ≥ k, there is a forkable substring ˇw of length at
least k.
Recall that the characteristic string w ∈ {0, 1}
R for such an execution of πiSPoS is determined
by assigning each wi = 1 independently with probability (1 − )/2. According to Theorem 4.13
the probability that a string of length t drawn from this distribution is forkable is no more than
exp(−c
√
t) for a positive constant c. Note that for any α ≥ 1,
4.4.1 Common prefix with covert adversaries
We revisit the notion of common prefix in the setting of covert adversaries. We define the covert
divergence of w to be the maximum divergence over all possible covert forks for w:
As in the setting with general adversaries, we wish to establish that a string with large covert
divergence must have a large covertly forkable substring. A direct analogue of Theorem 4.27 then
implies that characteristic strings arising from πiSPoS are unlikely to have large covert divergence
and, hence, possess the common prefix property against covert adversaries.
We record an analogue of Theorem 4.26 for covert adversaries.
Theorem 4.28. Let w ∈ {0, 1}
∗
. Then there is a covertly forkable substring wˇ of w with |wˇ| ≥
cdiv(w).
Proof. We are more brief, as portions of the proof have direct analogs in the proof of Theorem 4.26.
Consider a covert fork F ` w and a pair of viable tines (t1, t2) of F for which div(t1, t2) = cdiv(w);
we assume the tines are identified so that `(t1) < `(t2) and, as in the proof of the general case,
assume that this pair of tines minimizes the quantity |`(t2)−`(t1)| among all pairs with divergence
equal to cdiv(w).
Let y denote the last vertex on the tine t1 ∩ t2. In contrast to the setting with a general
adversary, it is not clear that y is honest and this motivates a slightly different choice for the
beginning of the string ˇw: define α to be the largest honest index of w on the tine t1 ∩ t2, with the
convention that α = 0 if there is no such index. As in the proof of Theorem 4.26, define β to be
the smallest honest index of w for which β ≥ `(t2), with the convention that β = n + 1 if there is
no such honest index. Then define ˇw = wα+1 . . . wβ−1; as in the proof of Theorem 4.26 it is easy
to confirm that |wˇ| = (β − 1) − α ≥ `(t1) − `(t1 ∩ t2) ≥ cdiv(w). The remainder of the proof argues
that ˇw is covertly forkable.
As in the proof of Theorem 4.26, the depth d(h) of any honest index h < β is no more
than min(length(t1), length(t2)): if h ≤ `(t1) this follows directly from the definition of viability. Otherwise, `(t1) < h < `(t2) and we consider the tine th labeled with h: if length(th) ≥
min(length(t1), length(t2)) then the tine th, coupled with either t1 or t2, would produce a pair
of tines with divergence no less than div(t1, t2), but for which |`(·) − `(·)| is strictly less than
|`(t1) − `(t2)|.
To complete the proof, we define an injective function i : H → A, where H denotes the set of
honest indices in {α+ 1, . . . , β −1} and A the complement—the set of adversarial indices of ˇw. The
existence of such a function implies that |H| ≤ |A| and hence that ˇw is covertly forkable by the
criterion given in Proposition 4.22. Let A0 ⊂ A denote the set of adversarial indices of ˇw appearing
as a label on either of the two tines t1 and t2. The function i is defined as follows: i(h), for an
honest index h ∈ H, is the smallest (adversarial) index of A0 which labels a vertex at depth equal
to d(h). Assuming that this function is well-defined it is clearly injective, as labels cannot appear
on multiple vertices of a covert fork and depths of honest vertices are pairwise distinct.
To confirm that i(h) is well-defined, note that for any h ∈ H we must have d(α) < d(h) ≤
min(length(t1), length(t2)) and hence there is at least one vertex v on each of t1 and t2 with depth
equal to d(h); furthermore, by the defining properties of α and β, this vertex is labeled with
an index of ˇw. If d(h) ≤ length(t1 ∩ t2), there is a common vertex v on these tines for which
length(v) = d(h); note that this vertex cannot be honest by the definition of α, so i(h) = `(v) is
well-defined in this case. If d(h) > length(t1 ∩ t2), the two tines have distinct vertices at depth
d(h), and one of these must then be adversarial—thus i(h) is well-defined in this case as well.
Finally, we remark that the proof of Theorem 4.27 applies with minor adaptations to the covert
case.
Theorem 4.29. Let k, R ∈ N and  ∈ (0, 1). The probability that the πiSPoS protocol, when executed
with a (1 − )/2 fraction of adversarial stake and a covert adversary, violates the common prefix
property with parameter k throughout a period of R is no more than exp(−Ω(k)+ln R); the constant
hidden by the Ω() notation depends only on .
Proof. The proof of Theorem 4.27 applies directly; in this case the asymptotics rely on Theorem 4.23
and the following bound applied in a way that the constant c depends only on .
4.5 Chain Growth and Chain Quality
Anticipating these two proofs, we record an additive Chernoff–Hoeffding bound. (See, e.g., [29] for
a proof.)
Theorem 4.30 (Chernoff–Hoeffding bound). Let X1, . . . , XT be independent random variables with
E[Xi
] = pi and Xi ∈ [0, 1]. Let X =
PT
i=1 Xi and µ =
PT
i=1 pi = E[X]. Then, for all δ ≥ 0,
We will start with the chain growth property.
Theorem 4.31. The πiSPoS protocol satisfies the chain growth property with parameters τ = 1 −
α, s ∈ N throughout an epoch of R slots with probability at least 1 − exp(−Ω(
2
s) + ln R) against an
adversary holding an α −  portion of the total stake.
Proof. Define Hama(α) to be the event that the Hamming weight ratio of the characteristic string
that corresponds to the slots [a, a + s − 1] is no more than α. Given that the adversarial stake
is α − , each of the k slots has probability α −  being assigned to the adversary and thus the
probability that the Hamming weight is more than αs drops exponentially in s. Specifically, using
the additive version of the Chernoff bound, we have that Pr[¬Hama(α)] ≤ exp(−2
2
s). It follows
that,
Given the above we know that when Hamα happens there will be at least (1 − α)s honest slots in
the period of s rounds. Given that each honest slot enables an honest party to produce a block,
all honest parties will advance by at least that many blocks. Using a union bound, it follows
that the speed coefficient can be set to τ = (1 − α) and it is satisfied with probability at least
1 − exp(−2
2
s + ln(R)).
Having established chain growth we now turn our attention to chain quality. Recall that the
chain quality property with parameters µ and ` asserts that among every ` consecutive blocks in a
chain (possessed by an honest user), the fraction of adversarial blocks is no more than µ.
Theorem 4.32. Let α −  be the adversarial stake ratio. The πiSPoS protocol satisfies the chain
quality property with parameters µ(α − ) = α/(1 − α) and ` ∈ N throughout an epoch of R slots
with probability at least.

Proof. First, from the proof for chain growth (Theorem 4.31), we know that with high probability a
segment of ` rounds will involve at least (1−α)` slots with honest leaders; hence the resulting chain
must advance by at least (1−α)` blocks. By similar reasoning, the adversarial parties are associated
with no more than α` slots, and thus can contribute no more than α` blocks to any particular chain
over this period. It follows that the associated chain possessed by any honest party contains a
fraction α/(1 − α) of adversarial blocks with probability 1 −exp(−Ω(
2 min(α, 1−α)`) + ln R).
5 Our Protocol: Dynamic Stake
5.1 Using a Trusted Beacon
In the static version of the protocol in the previous section, we assumed that stake was static during
the whole execution (i.e., one epoch), meaning that stake changing hands inside a given epoch does
not affect leader election. Now we put forth a modification of protocol πSPoS that can be executed
over multiple epochs in such a way that each epoch’s leader election process is parameterized by
the stake distribution at a certain designated point of the previous epoch, allowing for change i
in the stake distribution across epochs to affect the leader election process. As before, we construct the protocol in a hybrid model, enhancing the FLSD,F ideal functionality to now provide randomness and auxiliary information for the leader election process throughout the epochs (the enhanced functionality will be called FDLSD,F). We then discuss how to implement FDLSD,F using only FLSD,F and in this way reduce the assumption back to the simple common random string selected at setup.
Before describing the protocol for the case of dynamic stake, we need to explain the modification of FLSD,F so that multiple epochs are considered. The resulting functionality, FDLSD,F, allows stakeholders to query it for the leader selection data specific to each epoch. FDLSD,F is parameterized by the initial stake of each stakeholder before the first epoch e1 starts; in subsequent epochs, parties will take into consideration the stake distribution in the latest block of the previous epoch’s first R − 2k slots. Given that there is no predetermined view of the stakeholder distribution, the functionality FDLSD,F will provide only a random string and will leave the interpretation according to the stakeholder distribution to the party that is calling it. The effective stakeholder distribution is the sequence S1,S2,... defined as follows: S1 is the initial stakeholder distribution; for slots {(j − 1)R + 1,...,jR} for j ≥ 2 the effective stakeholder Sj is determined by the stake allocation that is found in the latest block with time stamp at most (j −1)R−2k, provided all honest parties agree on it, or is undefined if the honest parties disagree on it. The functionality FDLSD,F is defined in Figure 10.  We now describe protocol πDPoS, which is a modified version of πSPoS that updates its genesis block B0 (and thus the leader selection process) for every new epoch. The protocol also adopts an adaptation of the static maxvalidS function, defined so that it narrows selection to those chains which share common prefix. Specifically, it adopts the following rule, parameterized by a prefix length k:
Function maxvalid(C,C). Returns the longest chain from C ∪ {C} that does not fork from C more than k blocks. If multiple exist it returns C, if this is one of them, or it returns the one that is listed first in C.  Protocol πDPoS is described in Figure 11 and functions in the FDLSD,F-hybrid model.
Remark 1. The modification to maxvalid(·) to not diverge more than k blocks from the last chain possessed will require stakeholders to be online at least every k slots. The relevance of the rule
comes from the fact that as stake shifts over time, it will be feasible for the adversary to corrupt stakeholders that used to possess a stake majority at some point without triggering Bad1/2 and thus any adversarial chains produced due to such an event should be rejected. It is worth noting that this restriction can be easily lifted if one can trust honest stakeholders to securely erase their memory; in such case, a forward secure signature can be employed to thwart any past corruption attempt that tries to circumvent Bad1/2.
5.2	Simulating a Trusted Beacon
While protocol πDPoS handles multiple epochs and takes into consideration changes in the stake distribution, it still relies on FDLSD,F to perform the leader selection process. In this section, we show how to implement FDLSD,F through Protocol πDLS, which allows the stakeholders to compute the randomness and auxiliary information necessary in the leader election.
Recall, that the only essential difference between FLSD,F and FDLSD,F is the continuous generation of random strings ρ2,ρ3,... for epochs e2,e3,.... The idea is simple, protocol πDLS will use a coin tossing protocol to generate unbiased randomness that can be used to define the values ρj,j ≥ 2 bootstrapping on the initial random string and initial honest stakeholder distribution. However, notice that the adversary could cause a simple coin tossing protocol to fail by aborting. Thus, we build a coin tossing scheme with “guaranteed output delivery.”
Protocol πDLS is described in Figure 13 and uses a publicly verifiable secret sharing (PVSS)
[39].
As in the static stake case, we need to define an idealized protocol that behaves as if the computationally secure primitives that are employed in the real protocol behave perfectly. Once again we will base our combinatorial arguments on this idealized version. We remark that we depart πiSPoS as previously defined, adding further considerations about an ideal execution of the coin tossing procedure that generates randomness for the leader selection process. The assumption we will use about the PVSS scheme is that the resulting coin-flipping protocol simulates a perfect beacon with distinguishing advantage DLS. Simulation here suggests that, in the case of honest majority, there is a simulator that interacts with the adversary and produces indistinguishable protocol transcripts when given the beacon value after the commitment stage. We remark that using [39] as a PVSS, a simulator can achieve simulatability in the random oracle model by taking advantage of the programmability of the oracle. Using a random oracle is by no means necessary though and the same benefits may be obtained by a CRS embedded into the genesis block.
Commitments and Coin Tossing. A coin tossing protocol allows two or more parties to obtain a uniformly random string. A classic approach to construct such a protocol is by using commitment schemes. In a commitment scheme, a committer carries out a commitment phase, which sends evidence of a given value to a receiver without revealing it; later on, in an opening phase, the committer can send that value to the receiver and convince it that the value is identical to the value committed to in the commitment phase. Such a scheme is called binding if it is hard for the committer to convince the receiver that he was committed to any value other than the one for which he sent evidence in the commitment phase, and it is called hiding if it is hard for the receiver to learn anything about the value before the opening phase. We denote the commitment phase with randomness r and message m by Com(r,m) and the opening as Open(r,m).
In a standard two-party coin tossing protocol [9], one party starts by sampling a uniformly random string u1 and sending Com(r,u1). Next, the other party sends another uniformly random string u2 in the clear. Finally, the first party opens u1 by sending Open(r,u1) and both parties compute output u = u1 ⊕ u2. Note, however, that in this classical protocol the committer may selectively choose to “abort” the protocol (by not opening the commitment) once he observes the value u2. While this is an intrinsic problem of the two-party setting, we can avoid this problem in the multi-party setting by relying on a verifiable secret sharing scheme and an honest majority amongst the protocol participants.
Verifiable Secret Sharing (VSS). A secret sharing scheme allows a dealer PD to split a secret σ into n shares distributed to parties P1,...,Pn, such that no adversary corrupting up to t parties can recover σ. In a Verifiable Secret Sharing (VSS) scheme [22], there is the additional guarantee that the honest parties can recover σ even if the adversary corrupts the shares held by the parties that it controls and even if the dealer itself is malicious. We define a VSS scheme as a pair of efficient dealing and reconstruction algorithms (Deal,Rec). The dealing algorithm Deal(n,σ) takes as input the number of shares to be generated n along with the secret σ and outputs shares σ1,...,σn. The reconstruction algorithm Rec takes as input shares σ1,...,σn and outputs the secret σ as long as no more than t shares are corrupted (unavailable shares are set to ⊥ and considered corrupted). Schoenmakers [39] developed a simple VSS scheme based on discrete logarithms suitable for our purposes.
Constructing Protocol πDLS. The main problem to be solved when realizing FDLSD,F with a protocol run by the stakeholders is that of generating uniform randomness for the leader selection process while tolerating adversaries that may try to interfere by aborting or feeding incorrect information to parties. In order to generate uniform randomness ρj for epoch ej, j ≥ 2, the
Figure 12: The two stages of the protocol πDPoS that use the blockchain as a broadcast channel. elected stakeholders for epoch ej−1 will employ a coin tossing scheme for which all honest parties are guaranteed to receive output as long as there is an honest majority. The protocol has two stages, commit and reveal which are split into phases. The stages of the protocol are presented in Figure 12. The Commitment Phase covers the whole commitment stage, and proceeds as follows: for 1 ≤ i ≤ n, stakeholder Ui samples a uniformly random string ui ∈ {0,1}Rlogτ and randomness ri for the underlying commitment scheme, generates shares  ,...,σni , and posts Com(ri,ui) to the blockchain together with the encryptions of the all the shares under the public-key of each respective shareholder. After 4k slots, players remove the k most recent blocks of their chain, and if commitments from a majority of stakeholders are posted on the blockchain and shares from a majority of stakeholders have been received, the reveal stage starts (in the other case the protocol halts). In the reveal stage there are two phase: the Reveal Phase and the Recovery Phase. In the reveal phase, for 1 ≤ i ≤ n, stakeholder Ui posts Open(ri,ui) to the blockchain. After 4k slots players remove the most recent k blocks and identify all stakeholders that have issued openings of the form Open(ri,ui). In the final Recovery Phase, lasting 2k slots, if a stakeholder Ua that initially submitted a commitment is identified as not posting an opening to its commitment, the honest parties can post all shares σ1a,...,σna in order to use Rec(σ1a,...,σna) to reconstruct ua. Finally, each stakeholder uses the values ui obtained in the second round to compute ρj = Pi ui. Protocol πDLS is described in Figure 13. We remark that it is possible to run the reveal and recovery phases in parallel, however for improved efficiency we choose to run them sequentially.
5.3	Robust Transaction Ledger
We are now ready to state the main result of the section that establishes that the πDPOS protocol with the protocol πDLS as a sub-routine implements a robust transaction ledger under the environmental conditions that we have assumed. Recall that in the dynamic stake case we have to ensure that the adversary cannot exploit the way stake changes over time and corrupt a set of stakeholders that will enable the control of the majority of an elected committee of stakeholders in an epoch. In order to capture this dependency on stake “shifts”, we introduce the following property. Definition 5.1. Consider two slots sl1,sl2 and an execution E. The stake shift between sl1,sl2 is the maximum possible statistical distance of the two weighted-by-stake distributions that are defined using the stake reflected in the chain C1 of some honest stakeholder active at sl1 and the chain C2 of some honest stakeholder active at sl2 respectively.
Given the definition above we can now state the following theorem.
Theorem 5.2. Fix parameters k,R,L ∈ N,,σ ∈ (0,1). Let R = 10k be the epoch length and L the total lifetime of the system. Assume the adversary is restricted to 1−2 − σ relative stake and that the πSPOS protocol satisfies the common prefix property with parameters R,k and probability of error CP, the chain quality property with parameters µ ≥ 1/k,k and probability of error CQ and
the chain growth property with parameters τ ≥ 1/2,k and probability of error CG. Furthermore, assume that πDLS simulates a perfect beacon with distinguishing advantage DLS.
Then, the πDPOS protocol satisfies persistence with parameters k and liveness with parameters u = 2k throughout a period of L slots (or Bad1/2 happens) with probability  
DLS), assuming that σ is the maximum stake shift over 10k slots, corruption delay D ≥ 2R − 4k and no honest player is offline for more than k slots.
Proof. (sketch) Let us first consider the execution of πDPOS when FDLSD,F is used instead of πDLS. Let BADr be the event that any of the three properties CP,CQ,CG is violated at round r ≥ 1 while no violation of any of them occurred prior to r. It is easy to see that Pr[∪r≤RBADr] . Conditioning now on the negation of this event, we can repeat the argument for the second epoch, since D ≥ R and thus the adversary cannot influence the stakeholder selection for the second epoch.
It follows that Pr[∪r≤LBADr]   CP  ). It is easy now to see that persistence and liveness hold conditioning on the negation of the above event: a violation of persistence would violate common prefix. On the other hand, a violation of liveness would violate either chain growth or chain quality for the stated parameters.
Observe that the above result will continue to hold even if FDLSD,F was weakened to allow the adversary access to the random value of the next epoch 6k slots ahead of the end of the epoch.
This is because the corruption delay D ≥ 2R − 4k = 16k.
Finally, we examine what happens when FDLSD,F is substituted by FLSD,F and the execution of protocol πDLS. Consider an execution with environment Z and adversary A and event BAD that happens with some probability β in this execution. We construct an adversary A∗ that operates in an execution with FDLSD,F, weakened as in the previous paragraph, and induces the event BAD with roughly the same probability β. A∗ would operate as follows: in the first 4k slots, it will use an honest party to insert in the blockchain the simulated commitments of the honest parties; this is feasible for A∗ as in 4k slots, chain growth will result in the blockchain growing by at least 2k blocks and thus in the first k blocks there will be at least a single honest block included. Now A∗ will obtain from FDLSD,F the value of the beacon and it will simulate the opening of all the commitments on behalf of the honest parties. Finally, in the last 2k slots it will perform the forced opening of all the adversarial commitments that were not opened. The protocol simulation will be repeated for each epoch and the statement of the theorem follows. 
Remark 2. We note that it is easy to extend the adversarial model to include fail-stop (and recover) corruptions in addition to Byzantine corruptions. The advantage of this mixed corruption setting, is that it is feasible to prove that we can tolerate a large number of fail-stop corruptions (arbitrarily above 50%). The intuition behind this is simple: the forkable string analysis still applies even if an arbitrary percentage of slot leaders is rendered inactive. The only necessary provision for this would be expand the parameter k inverse proportionally to the rate of non-stopped parties. We omit further details.
6	Anonymous Communication and Stronger Adversaries
The protocols constructed in the previous section are proven secure against delayed adaptive corruptions, meaning that, after requesting to corrupt a given party Ui, the adversary has to wait for D slots before the corruption actually happens. However it is desirable to make D as small as possible, or even eliminate it altogether to achieve security against a standard adaptive adversary.
The delay is required because the adversary must not be able to corrupt parties once it knows that they are the slot leaders for a given slot. However, notice that the slot leaders are selected by weighting public keys by stake, while the adversary can only choose to corrupt a user Ui without knowing its public key. Thus, the adversary must be able to observe communication between Ui and the Diffuse functionality in order to determine which public key is associated with user Ui and detect when Ui is selected as a slot leader. We will show that we can eliminate the delay by extending our model with a sender anonymous broadcast channel (provided by the Diffuse functionality) and having the environment activate all parties in every round. We introduce the following modifications in the ideal functionalities:
•	Diffuse Functionality: The functionality will work as described in Section 2 except that it will remove all information about the sender Us of every message before delivering it to the receiver Ur’s inbox (input tape), thus ensuring that the sender remain anonymous. 
•	Key and Transaction Functionality: The functionality will work as described in Section 2 except that it will allow immediate corruption of a user U upon receiving a message (Corrupt,U) from the adversary.
Apart from these modifications in the ideal functionalities, we also change the environment behavior by requiring that it activates all users at every slot slj. Having all parties being activated at every slot results in an anonymity set of size equal to the number of honest parties, making it difficult for the adversary to associate a given public key with a user (i.e. any of the honest parties could be associated with a given public key that is not associated with a corrupted party). In this extended model we can reprove Theorem 5.2 without a delay D by strengthening the restrictions that are imposed on the environment in the following way.
•	We will say the adversary is restricted to less than 50% relative stake for windows of length D if for all sets of consecutive slots of length D, the sum over all corrupted keys of the maximum stake held by each key during this period of D slots (in any possible Sj(r) where Uj is an honest party) is no more than 50% of the minimum total stake during this period. In case the above is violated an event Bad1D/2 becomes true for the given execution.
Using the above strengthened condition, we can remove the corruption delay requirement D in Theorem 5.2 by assuming that Bad1/2 is substituted with Bad1D/2.
7	Incentives
So far our analysis has focused on the cryptographic adversary setting where a set of honest players operate in the presence of an adversary. In this section we consider the setting of a coalition of rational players and their incentives to deviate from honest protocol operation.
7.1	Input Endorsers
In order to address incentives, we modify further our basic protocol to assign two different roles to stakeholders. As before in each epoch there is a set of elected stakeholders that runs the secure multiparty coin flipping protocol and are the slot leaders of the epoch. Together with those there is a (not necessarily disjoint) set of stakeholders called the endorsers. Now each slot has two types of stakeholders associated with it; the slot leader who will issue the block as before and the slot endorser who will endorse the input to be included in the block. Moreover, contrary to slot leaders, we can elect multiple slot endorsers for each slot, nevertheless, without loss of generality we just assume a single input endorser per slot in this description. While this seems like an insignificant modification it gives us a room for improvement because of the following reason: endorsers’ contributions will be acceptable even if they are d slots late, where d ∈ N is a parameter.
Note that in case no valid endorser input is available when the slot leader is about to issue the block, the leader will go ahead and issue an empty block, i.e., a block without any actual inputs (e.g., transactions in the case of a transaction ledger). Note that slot endorsers just like slot leaders are selected by weighing by stake and thus they are a representative sample of the stakeholder population. In the case of a transaction ledger the same transaction might be included by many input endorsers simultaneously. In case that a transaction is multiply present in the blockchain its first occurrence only will be its “canonical” position in the legder. The enhanced protocol, πDPOSwE, can be easily seen to have the same persistence and liveness behaviour as πDPOS: the modification with endorsers does not provide any possibility for the adversary to prevent the chain from growing, accepting inputs, or being consistent. However, if we measure chain quality in terms of number of endorsed inputs included this produces a more favorable result: it is easy to see that the number of endorsed inputs originating from a set of stakeholders S in any k-long portion of the chain is proportional to the relative stake of S with high probability. This stems from the fact that it is sufficient that a single honest block is created for all the endorsed inputs of the last d slots to be included in it. Assuming d ≥ 2k, any set of stakeholders S will be an endorser in a subset of the d slots with probability proportional to its cumulative stake, and thus the result follows.
As in bitcoin, stakeholders that issue blocks are incentivized to participate in the protocol by collecting transaction fees. Contrary to bitcoin, of course, one does not need to incentivize stakeholders to invest computational resources to issue blocks. Rather, availability and transaction verification should be incentivized. Nevertheless, they have to be incentivized to be online often.
Any stakeholder, at minimum, must be online and operational in the following circumstances.
•	In the slot prior to a slot she is the elected shareholder so that she queries the network and obtains the currently longest blockchain as well as any endorsed inputs to include in the block.
•	In the slot during which she is the elected shareholder so that she issues the block containing the endorsed inputs.
•	In a slot during the commit stage of an epoch where she is supposed to issue the VSS commitment of her random string.
•	In a slot during the reveal stage of an epoch where she is supposed to issue the required opening shares as well as the opening to her commitment.
•	In general, in sufficient frequency, to check whether she is an elected shareholder for the next or current epoch.
•	In a slot during which she is the elected input endorser so that she issues the endorsed input (e.g., the set of transactions) that requires processing all available transactions and verifying them.
In order to incentivize the above actions in the setting of a transaction ledger, fees can be collected from those that issue transactions to be included in the ledger which can then be transfered to the block issuers. In bitcoin, for instance, fees can be collected by the miner that produces a block of transactions as a reward. In our setting, similarly, a reward can be given to the parties that are issuing blocks and endorsing inputs. The reward mechanism does not have to be block dependent as advocated in [34]. In our setting, it is possible to collect all fees of transactions included in a sequence of blocks in a pool and then distribute that pool to all shareholders that participated during these slots. For example, all input endorsers that were active may receive reward proportional to the number of inputs they endorsed during a period of rounds (independently of the actual number of transactions they endorsed). Other ways to distribute transaction fees are also feasible (including the one that is used by bitcoin itself—even though the bitcoin method is known to be vulnerable to attacks, e.g., the selfing-mining attack).
The reward mechanism that we will pair with input endorsers operates as follows. First we set the endorsing acceptance window, d to be d = 2k. Let C be a chain consisting of blocks
B0,B1,.... Consider the sequence of blocks that cover the j-th epoch denoted by B1,...,Bs with timestamps in {jR + 1,...,(j + 1)R + 2k} that contain an r ≥ 0 sequence of endorsed inputs that originate from the j-th epoch (some of them may be included as part of the j + 1 epoch). We define the total reward pool PR to be equal to the sum of the transaction fees that are included in the endorsed inputs that correspond to the j-th epoch. If a transaction occurs multiple times (as part of different endorsed inputs) or even in conflicting versions, only the first occurrence of the transaction is taken into account (and is considered to be part of the ledger at that position) in the calculation of P, where the total order used is induced by the order the endorsed inputs that are included in C. In the sequence of these blocks, we identify by L1,...,LR the slot leaders corresponding to the slots of the epoch and by E1,...,Er the input endorsers that contributed the sequence of r endorsed inputs. Subsequently, the i-th stakeholder Ui can claim a reward up to the amount (β ·|{j | Ui = Ej}|/r +(1−β)·|{j | Ui = Lj}|/R)P where β ∈ [0,1]. Claiming a reward is performed by issuing a “coinbase” type of transaction at any point after 4k blocks in a subsequent epoch to the one that a reward is being claimed from.
Observe that the above reward mechanism has the following features: (i) it rewards elected committee members for just being committee members, independently of whether they issued a block or not, (ii) it rewards the input endorsers with the inputs that they have contributed. (iii) it rewards entities for epoch j, after slot jR + 4k.
We proceed to show that our system is a δ-Nash (approximate) equilibrium, cf. [31, Section 2.6.6]. Specifically, the theorem states that any coalition deviating from the protocol can add at most an additive δ to its total rewards.
A technical difficulty in the above formulation is that the number of players, their relative stake, as well as the rewards they receive are based on the transactions that are generated in the course of the protocol execution itself. To simplify the analysis we will consider a setting where the number of players is static, the stake they possess does not shift over time and the protocol has negligible cost to be executed. We observe that the total rewards (and hence also utility by our assumption on protocol costs) that any coalition V of honest players are able extract from the execution lasting L = tR + 4k + 1 slots, is equal to for any execution E where common prefix holds with parameter k, where rj is the total endorsed inputs emitted in the j-th epoch (and possibly included at any time up to the first 2k slots of epoch j + 1), Pall(j) is the reward pool of epoch j, SLjV (E) is the number of times a member of V was elected to be a slot leader in epoch j and IEVj (E) the number of times a member of V was selected to endorse an input in epoch j.
Observe that the actual rewards obtained by a set of rational players V in an execution E might be different from RV (E); for instance, the coalition of V may never endorse a set of inputs in which case they will obtain a smaller number of rewards. Furthermore, observe that we leave the value of RV (E) undefined when E is an execution where common prefix fails: it will not make sense to consider this value for such executions since the view of the protocol of honest parties can be divergent; nevertheless this will not affect our overall analysis since such executions will happen with sufficiently small probability.
We will establish the fact that our protocol is a δ-Nash equilibrium by proving that the coalition V , even deviating from the proper protocol behavior, it cannot obtain utility that exceeds RV (E)+δ for some suitable constant δ > 0.
Theorem 7.1. Fix any δ > 0; the honest strategy in the protocol is a δ-Nash equilibrium against any coalition commanding a proportion of stake less than (1 − )/2 − σ for some constants ,σ ∈ (0,1) as in Theorem 5.2, provided that the maximum total rewards Pall provided in all possible protocol executions is bounded by a polynomial in λ, while CQ + CP + CG + DLS is negligible in λ.
Proof sketch. Consider a coalition of rational players V restricted as in the statement of the theorem, that engages in a protocol execution together with a number of other players that follow the protocol faithfully for a total number of L epochs. We will show that any deviation from the protocol will not result in substantially higher rewards for V . Observe that based on Theorem 5.2, no matter the strategy of V , with probability 1 − (L/R)(CQ + CP + CG) the protocol will enable all users to obtain the rewards they are entitled to as slot leaders and input endorsers. The latter stems from the following. First, from persistence and liveness, at least one honest block will be included every k blocks and hence, in each epoch, all input endorsers that follow the protocol will have the opportunity to act as input endorsers as many times they were elected to be. Second, the rewards received will be proportional to the times each party is an input endorser and issued a block successfully as well as equal to the number of times it is a slot leader. We observe that except with probability (L/R)(CQ+CP+CG) the utility received by coalition V is equal to RV . It follows that player V has expected utility at most E PAll, where PAll is the maximum amount of rewards produced in the lifetime of all possible executions. The result follows by the assumption in the statement of the theorem since (L/R)( .  
Remark 3. In the above theorem, for simplicity, we assumed that protocol costs are not affecting the final utility (in essence this means that protocol costs are assumed to be negligible). Nevertheless, it is straightforward to extend the proof to cover a setting where a negative term is introduced in the payoff function for each player proportional to the number of times inputs are endorsed and the number of messages transmitted for the MPC protocol. The proof would be resilient to these modifications because endorsed inputs and MPC protocol messages cannot be stifled by the adversary and hence the reward function can be designed with suitable weights for such actions that offsets their cost. Still note that the rewards provided are assumed to be “flat” for both slots and endorsed inputs and thus the costs would also have to be flat. We leave for future work the investigation of a more refined setting where costs and rewards are proportional to the actual computational steps needed to verify transactions and issue blocks.
Remark 4. The reward function described, only considers the number of times an entity was an input endorser without considering the amount of work that was put to verify the given transactions. Furthermore it is not sensitive to whether a slot leader issued a block or not in its assigned time slot. We next provide some context behind these choices. First suppose that slot leaders do not receive a reward when they do not issue a block. It is easy to see that when all parties follow the protocol the parties will receive the proportion from the reward pool that is associated to block issuance roughly proportional to their stake. Nevertheless, a malicious coalition can easily increase the ratio of these rewards by performing a block withholding attack (in this case this would amount to a selfish mining attack). Given that this happens with non-negligible probability a straightforward definition of RV (E) that respects this assignment is vulnerable to attack and hence a δ-Nash equilibrium theorem cannot be shown. Next, we consider the case of extending the reward function so that input endorsers that are rewarded based on the transactions they verify (as opposed to the flat reward we considered in the above theorem). Special care is necessary to design this function. Indeed the straightforward way to implement it, which is if the first input endorser to verify a transaction that is part of the pool can make a higher claim for its fee, then there is a strategy for an adversary to deviate from the protocol and improve its ratio of rewards: perform block withholding and/or endorsed input censorship to remove endorsed inputs from the blockchain that originate to honest parties. Then include the removed transactions in endorsed input that will be transmitted in the last possible opportunity. As before, given the attack, the natural way to define RV (E) is susceptible to it and hence a δ-Nash equilibrium theorem cannot be shown.
A possible direction for ameliorating the problem raised in Remark 4 above, is to share the transaction fee between all the input endorsers that endorsed it. This suggests the following modification to the protocol: whenever you are an input endorser you should attempt to include all transactions that you have collected for a sequence of k slots and retransmit your endorsed input in case it is removed from the main chain. We leave the analysis of such class of reward mechanisms for future work.
8	Stake Delegation
As discussed in the previous section, stakeholders must be online in order to generate blocks when they are selected as slot leaders. However, this might be unattractive to stakeholders with a small stake in the system. Moreover, requiring that a majority of elected stakeholders participate in the coin tossing protocol for refreshing randomness introduces a strain on the on the stakeholders and the network, since it might require broadcasting and storing a large number of commitments and shares.
We mitigate these issues by providing a method for reducing the size of the group of stakeholders that engage in the coin tossing protocol. Instead of the elected stakeholders directly forming the committee that will run coin tossing, a group of delegates will act on their behalf. In more detail, we put forth a delegation scheme, whereby stakeholders will authorize other entities, called delegates, who may be stakeholders themselves, to represent them in the coin tossing protocol. A delegate may participate in the protocol only if it represents a certain number of stakeholders whose aggregate stake exceeds a given threshold. Such a participation threshold ensures that a “fragmentation” attack, that aims to increase the delegate population in order to hurt the performance of the protocol, cannot incur a large penalty as it is capable to force the size of the committee that runs the protocol to be small (it is worth noting that the delegation mechanism is similar to mining pools in proof-of-work blockchain protocols).
8.1	Minimum Committee Size
To appreciate the benefits of delegation, recall that in the basic protocol (πDPoS) a committee member selected by weighing by stake is honest with probability 1/2 +  (this being the fraction of the stake held by honest players). Thus, the number of honest players selected by k invocations of weighing by stake is a binomial distribution. We are interested in the probability of a malicious majority, which can be directly controlled by a Chernoff bound.  Consider the case that  = 0.05; then we have the bound exp(−0.00138 · k) which provides an error of 1/1000 as long as k ≥ 5000. Similarly, in the case  = 0.1, we have the bound exp(−0.00625k) which provides the same error for k ≥ 1100.
We observe that in order to withstand a significant number of epochs, say 215 (which, if we equate a period with one day, will be 88 years), and require error probability 2−40, we need that k ≥ 32648.
In cases where the wealth in the system is not concentrated among a small set of stakeholders the above choice is bound to create a very large committee. (Of course, the maximum size of the committee is k.)
8.2	Delegation Scheme.
The concept of delegation is simple: any stakeholder can allow a delegate to generate blocks on her behalf. In the context of our protocol, where a slot leader signs the block it generates for a certain slot, such a scheme can be implemented in a straightforward way based on proxy signatures [10].
A stakeholder can transfer the right to generate blocks by creating a proxy signing key that allows the delegate to sign messages of the form (st,d,slj) (i.e., the format of messages signed in Protocol πDPoS to authenticate a block). In order to limit the delegate’s block generation power to a certain range of epochs/slots, the stakeholder can limit the proxy signing key’s valid message space to strings ending with a slot number slj within a specific range of values. The delegate can use a proxy signing key from a given stakeholder to simply run Protocol πDPoS on her behalf, signing the blocks this stakeholder was elected to generate with the proxy signing key. This simple scheme is secure due to the Verifiability and Prevention of Misuse properties of proxy signature schemes, which ensure that any stakeholder can verify that a proxy signing key was actually issued by a specific stakeholder to a specific delegate and that the delegate can only use these keys to sign messages inside the key’s valid message space, respectively. We remark that while proxy signatures can be described as a high level generic primitive, it is easy to construct such schemes from standard digital signature schemes through delegation-by-proxy as shown in [10]. In this construction, a stakeholder signs a certificate specifying the delegates identity (e.g., its public key) and the valid message space. Later on, the delegate can sign messages within the valid message space by providing signatures for these messages under its own public key along with the signed certificate. As an added advantage, proxy signature schemes can also be built from aggregate signatures in such a way that signatures generated under a proxy signing key have essentially the same size as regular signatures [10].
An important consideration in the above setting is the fact that a stakeholder may want to withdraw her support to a stakeholder prior to its proxy signing key expiration. Observe that proxy signing keys can be uniquely identified and thus they may be revoked by a certificate revocation list within the blockchain.
8.2.1	Eligibility threshold
Delegation as described above can ameliorate fragmentation that may occur in the stake distribution. Nevertheless, this does not prevent a malicious stakeholder from dividing its stake to multiple accounts and, by refraining from delegation, induce a very large committee size. To address this, as mentioned above, a threshold T, say 1%, may be applied. This means that any delegate representing less a fraction less than T of the total stake is automatically barred from being a committee member. This can be facilitated by redistributing the voting rights of delegates representing less than T to other delegates in a deterministic fashion (e.g., starting from those with the highest stake and breaking ties according to lexicographic order). Suppose that a committee has been formed,
C1,...,Cm, from a total of k draws of weighing by stake. Each committee member will hold ki such votes where Pmi=1 ki = k. Based on the eligibility threshold above it follows that m ≤ T−1 (the maximum value is the case when all stake is distributed in T−1 delegates each holding T of the stake).
9	Attacks Discussion
We next discuss a number of practical attacks and indicate how they are reflected by our modeling and mitigated.
Double spending attacks In a double spending attack, the adversary wishes to revert a transaction that is confirmed by the network. The objective of the attack is to issue a transaction, e.g., a payment from an adversarial account holder to a victim recipient, have the transaction confirmed and then revert the transaction by, e.g., including in the ledger a second conflicting transaction. Such an attack is not feasible under the conditions of Theorem 5.2. Indeed, persistence ensures that once the transaction is confirmed by an honest player, all other honest players from that point on will never disagree regarding this transaction. Thus it will be impossible to bring the system to a state where the confirmed transaction is invalidated (assuming all preconditions of the theorem hold). See the next section for an experimental discussion about double spending.
Grinding attacks In stake grinding attacks, the adversary tries to influence the slot leader selection process to improve its chances of being selected to generate blocks (which can be used to perform other attacks such as double spending). Basically, when generating a block that is taken as input by the slot leader selection process, the adversary first tests several possible block headers and content in order to find the one that gives it the best chance of being selected as a slot leader again in the future. While this attack affects PoS based cryptocurrencies that collect randomness for the slot leader selection process from raw data in the blockchain itself (i.e. from block headers and content), our protocol uses a standard coin tossing protocol that is proven to generate unbiased uniform randomness as discussed in Section 5.2. We show that an adversary cannot influence the randomness generated in Figure 13, which is guaranteed to be uniformly random, thus guaranteeing that slot leaders are selected with probability proportional to their stake.
Transaction denial attacks In a transaction denial attack, the adversary wishes to prevent a certain transaction from becoming confirmed. For instance, the adversary may want to target a specific account and prevent the account holder from issuing an outgoing transaction. Such an attack is not feasible under the conditions of Theorem 5.2. Indeed, liveness ensures that, provided the transaction is attempted to be inserted for a sufficient number of slots by the network, it will be eventually confirmed.
Desynchronization attacks In a desynchronization attack, a shareholder behaves honestly but is nevertheless incapable of synchronizing correctly with the rest of the network. This leads to ill-timed issuing of blocks and being offline during periods when the shareholder is supposed to participate. Such an attack can be mounted by preventing the party’s access to a time server or any other mechanism that allows synchronization between parties. Moreover, a desynchronization may also occur due to exceedingly long delays in message delivery. Our model allows parties to become desynchronized by incorporating them into the adversary. No guarantees of liveness and persistence are provided for desynchronized parties and thus we can get security as long as parties with less than 50% of stake get desynchronized. If more than parties get desynchronized our protocol can fail. More general models like partial synchrony [19, 35] are interesting to consider in the PoS design setting.
Eclipse attacks In an eclipse attack, message delivery to a shareholder is violated due to a subversion in the peer-to-peer message delivery mechanism. As in the case of desynchronization attacks, our model allows parties to be eclipse attacked by incorporating them into the adversary. No guarantees of liveness or persistence are provided for such parties.
51% attacks A 51% attack occurs whenever the adversary controls more than the majority of the stake in the system. It is easy to see that any sequence of slots in such a case is with very high probability forkable and thus once the system finds itself in such setting the honest stakeholders may be placed in different forks for long periods of time. Both persistence and liveness can be violated.
Bribery Attacks In bribery attacks [11], an adversary deliberately pays miners (through cryptocurrencies or fiat money) to work on specific blocks and forks, aiming at generating an arbitrary fork that benefits the adversary (e.g. by supporting a double spending attack). Miners of PoW based cryptocurrencies do not have to own any stake in order to mine blocks, which makes this attack strategy feasible. In this setting, if the adversary offers a bribe higher than the reward for correctly generating a block, any rational miner has a clear incentive to accept the bribe and participate in the attack since it increases the miner’s financial outcome. However, in our PoS based protocol, malicious slot leaders who agree to deliberately attack the system not only risk to forego any potential profit they would earn from behaving honestly but may also risk to lose equity. Notice that slot leaders must have money invested in the system in order to be able to generate blocks and if an attack against the system is observed it might bring currency value down. Even if the bribe is higher than the reward for correct behavior, the loss from currency devaluation can easily offset any additional profits made by participating in this attack. Hence, bribery attacks may be be less effective against a PoS based consensus protocol than a PoW based one. Currently our rationality model does not formally encompass this attack strategy and investigating its efficacy against PoS based consensus protocols is left as a future work.
Long-range attacks An attacker who wishes to double spend at a later point in time can mount a long-range attack [12] by computing a longer valid chain that starts right after the genesis block where it is the single stakeholder actively participating in the protocol. Even if this attacker owns a small fraction of the total stake, it can locally compute this chain generating only the blocks for slots where it is elected the slot leader and keep generating blocks ahead of current time until its alternative chain has more blocks than the main chain. Now, the attacker can post a transaction to the main chain, wait for it to be confirmed (and for goods to be delivered in exchange for the transaction) and present the longer alternative chain to invalidate its previously confirmed transaction. This attack is ineffective against Ouroboros for two reasons: Protocol πDLS will only output valid leader selection data allowing for the protocol to continue if a majority of the stakeholders participate (or have delegates participate on their behalf) and stakeholders will reject blocks generated for slots that are far ahead of time. Since the alternative chain is generated artificially with blocks and protocol messages generated solely by an attacker who controls a small fraction of the stake the leader selection data needed to start new epochs will be considered invalid by other nodes. Even if the attacker could find a strategy to generate an alternative chain with valid leader selection data, presenting this chain and its blocks generated at slots that are far ahead of time would not result in a successful attack since those blocks far ahead of time would be rejected by the honest stakeholders and the final alternative chain would be shorter than the main chain.
Nothing at stake attacks The “nothing at stake” problem refers in general to attacks against PoS blockchain systems that are facilitated by shareholders continuing simultaneously multiple blockchains exploiting the fact that little computational effort is needed to build a PoS blockchain. Provided that stakeholders are frequently online, nothing at stake is taken care of by our analysis of forkable strings (even if the adversary brute-forces all possible strategies to fork the evolving blockchain in the near future, there is none that is viable), and our chain selection rule that instructs players to ignore very deep forks that deviate from the block they received the last time they were online. It is also worth noting that, contrary to PoW-based blockchains, in our protocol it is infeasible to have a fork generated in earnest by two shareholders. This is because slots are uniquely assigned and thus at any given moment there is a single uniquely identified shareholder that is elected to advance the blockchain. Players following the longest chain rule will adopt the newly minted block (unless the adversary presents at that moment an alternative blockchain using older blocks). It is remarked in [13] that the “tragedy of commons” might lead stakeholders in some PoS based schemes to adhere to attacks because they do not have the power to deter attacks by themselves and would incur financial losses even if they did not join the attack. This would lead rational stakeholders to accept small bribes in alternative currencies that might at least obtain some financial gain. However, in the incentive structure of Ouroboros, slot leaders and endorsers who could potentially join an attack would receive rewards in both the main and the adversarial chain, resulting in those stakeholders not achieving higher profits by joining the attack.
Past majority attacks As stake moves our assumption is that only the current majority of stakeholders is honest. This means that past account keys (which potentially do not hold any stake at present) may be compromised. This leads to a potential vulnerability for any PoS system since a set of malicious shareholders from the past can build an alternative blockchain exploiting such old accounts and the fact that it is effortless to build such a blockchain. In light of Theorem 5.2 such attack can only occur against shareholders who are not frequently online to observe the evolution of the system or in case the stake shifts are higher than what is anticipated by the preconditions of the theorem. This can be seen a special instance of the nothing at stake problem, where the attacker no longer owns any stake in the system and is thus free from any financial losses when conducting the attack.
Selfish-mining In this type of attack, an attacker withholds blocks and releases them strategically attempting to drop honestly generated blocks from the main chain. In this way the attacker reduces chain growth and increases the relative ratio of adversarially generated blocks. In conventional reward schemes, as that of bitcoin, this has serious implications as it enables the attacker to obtain a higher rate of rewards compared to the rewards it would be receiving in case it was following the honest strategy. Using our reward mechanism however, selfish mining attacks are neutralized. The intuition behind this, is that input endorsers, who are the entities that receive rewards proportionally to their contributions, cannot be stifled because of block withholding: any input endorser can have its contribution accepted for a sufficiently long period of time after its endorsement took place, thus ensuring it will be incorporated into the blockchain (due to sufficient chain quality and chain growth). Given that input endorsers’ contributions are (approximately) proportional to their stake this ensures that reward distribution cannot be affected substantially by block withholding.
10	Experimental Results
We have implemented a prototype instantiation of Ouroboros in Haskell as well as in the Rustbased Parity Ethereum client in order to evaluate its concrete performance. More specifically, we have implemented Protocol πDPoS using Protocol πDLS to generate leader selection parameters (i.e., generating fresh randomness for the weighed stake sampling procedure). For this instantiation, we use the PVSS scheme of [39] implemented over the elliptic curve secp256r1. This PVSS scheme’s share verification information includes a commitment to the secret, which is also used as the commitment specified in protocol πDLS; this eliminates the need for a separate commitment to be generated and stored in the blockchain. In order to obtain better efficiency, the final output ρ of Protocol πDLS is a uniformly random binary string of 32 bytes. This string is then used as a seed for a PRG (ChaCha in our implementation, [8]) and stretched into R random labels of logτ bits corresponding to each slot in an epoch. The weighing by stake leader selection process is then implemented by using the random binary string associated to each epoch to perform the sequence of coin-flips for selecting a stakeholder. The signature scheme used for signing blocks is ECDSA, also implemented over curve secp256r1.
10.1	Transaction Confirmation Time Under Optimal Network Conditions
We first examine the time required for confirming a transaction in a setting where the network is not under substantial load and transactions are processed as they appear.
Figure 14: Transaction confirmation times in minutes that achieve assurance 99.9% against a hypothetical double spending attack with different levels of adversarial power for Bitcoin and Ouroboros (both covert and general adversaries).
In Fig. 14 we lay out a comparison in terms of transaction confirmation time between Bitcoin and Ouroboros showing how much a verifier has to wait to be sure that the best possible  doublespending attack succeeds with probability less than 0.1%. In the case of Bitcoin, we consider a double-spending attacker that commands a certain percentage of total hashing power and wishes to revert a transaction. The attacker attempts to double-spend via a block-witholding attack as described in the same paper (the attacker mines a private fork and releases it when it is long enough). In the case of Ouroboros we consider a double spending attacker that attempts to brute force the space of all possible forks for the current slot leader distribution in a certain segment of the protocol and commands a certain percentage of the total stake. We consider both the covert and the general adversarial setting for Ouroboros.
In all of the scenarios, we measure the number of minutes that one has to wait in order to achieve probability of double spending less than 0.1%. In Fig. 15 we present a graph that illustrates the speedup graphically.
We note that the above measurements compare our Ouroboros implementation with Bitcoin in the way the two systems are parameterized (with 10 minute block production rate for Bitcoin and 20 second slots for Ouroboros, a conservative parameter selection). Exploring alternative parameterizations for Bitcoin (such as making the proof-of-work easier) can speed up the transaction processing, nevertheless this cannot be done without carefully measuring the impact on overall security.
10.2	Absolute Performance of Ouroboros
We implemented Ouroboros as an instance of the Rust-based Ethereum Parity client.9 Subsequently, experiments were run using Amazon’s Elastic Compute Cloud (EC2) ‘c4.2xlarge‘ instances in the ‘us-east-1‘ region with a smaller “runner” instance responsible for coordinating each of the “worker” instances.
Each experiment consists of several steps:
Figure 15: Ouroboros vs. Bitcoin speedup of transaction confirmation time against a hypothetical double spending attacker for assurance level 99.9%. Ouroboros is at least 10 to 5 times faster for regular adversaries and 16 to 10 times faster for covert adversaries.
1.	Each worker instance builds a clean Docker image containing a specific revision of our fork of the Parity software  containing the Ouroboros proof-of-concept changes based on the Parity 1.6.8 release.
2.	Each worker instance is started in an “isolated” mode where none of the nodes talk to each other. During this period, a Parity account is recovered on each node and a start time for the network is established.
3.	Each worker instance is restarted in a production mode that allows communication between the nodes and transactions to be mined.
4.	A single worker instance is informed about all the other nodes. All nodes become aware of all other nodes via Parity’s peer-to-peer discovery methods.
5.	Each worker instance has a number of transactions generated and ingested.
In each experiment, 650,000 total transactions are generated between the participating nodes who shared stake equally. The amount transferred in any given transaction is small enough to avoid any account running out of funds. Each instance generates all the transactions using a hardcoded shared random seed, then keeps the transactions originating from the local user account. 20 transactions are saved in a single JSON file, ready to be directly passed to the Parity RPC endpoint using the ‘curl‘ command line tool. During ingestion, a single file of 20 transactions is ingested and one second is spent idle between each file to avoid overwhelming the instances with too many requests.
Various setups were tested, focusing on adjusting the Ouroboros slot duration and the number of participating nodes. 10, 20, 30, and 40 nodes were tested, ultimately limited by the number of
instances allowed in a single EC2 region. Slot durations of 5, 10, and 20 seconds were also tested. Variance between experiments was small. In Figure 16 we present the case of 40 nodes and slot length of 5 seconds that exhibits a median value of 257.6 transaction per second.
11	Acknowledgements
We thank Ioannis Konstantinou who contributed in a preliminary version of our protocol. We thank Lars Bru¨njes, Duncan Coutts, Kawin Worrasangasilpa for comments on previous drafts of the article. We thank Peter Gaˇzi for comments on previous drafts of the article and assisting us to generalize Theorem 4.26 to viable forks. We thank George Agapov for the prototype implementation of our protocol in Haskell and Jake Goulding for the Parity based implementation.
References
[1]	Noga Alon and Joel Spencer. The Probabilistic Method. Wiley, 3rd edition, 2008.
[2]	Giuseppe Ateniese, Ilario Bonacina, Antonio Faonio, and Nicola Galesi. Proofs of space: When space is of the essence. In Michel Abdalla and Roberto De Prisco, editors, Security and Cryptography for Networks - 9th International Conference, SCN 2014, Amalfi, Italy, September 3-5, 2014. Proceedings, volume 8642 of Lecture Notes in Computer Science, pages 538–557. Springer, 2014.
[3]	Yonatan Aumann and Yehuda Lindell. Security against covert adversaries: Efficient protocols for realistic adversaries. J. Cryptology, 23(2):281–343, 2010.
[4]	Iddo Bentov, Ariel Gabizon, and Alex Mizrahi. Cryptocurrencies without proof of work. CoRR, abs/1406.5694, 2014.
[5]	Iddo Bentov, Charles Lee, Alex Mizrahi, and Meni Rosenfeld. Proof of activity: Extending bitcoin’s proof of work via proof of stake [extended abstract]y. SIGMETRICS Performance Evaluation Review, 42(3):34–37, 2014.
[6]	Iddo Bentov, Rafael Pass, and Elaine Shi. The sleepy model of consensus. IACR Cryptology ePrint Archive, 2016:918, 2016.
[7]	Iddo Bentov, Rafael Pass, and Elaine Shi. Snow white: Provably secure proofs of stake. IACR Cryptology ePrint Archive, 2016:919, 2016.
[8]	Daniel J. Bernstein. Chacha, a variant of salsa20. In SASC: The State of the Art of Stream Ciphers., 2008.
[9]	Manuel Blum. Coin flipping by telephone. In Allen Gersho, editor, Advances in Cryptology: A Report on CRYPTO 81, CRYPTO 81, IEEE Workshop on Communications Security, Santa Barbara, California, USA, August 24-26, 1981., pages 11–15. U. C. Santa Barbara, Dept. of Elec. and Computer Eng., ECE Report No 82-04, 1981.
[10]	Alexandra Boldyreva, Adriana Palacio, and Bogdan Warinschi. Secure proxy signature schemes for delegation of signing rights. J. Cryptology, 25(1):57–115, 2012.
[11]	Joseph Bonneau. Why buy when you can rent? - bribery attacks on bitcoin-style consensus. In Jeremy Clark, Sarah Meiklejohn, Peter Y. A. Ryan, Dan S. Wallach, Michael Brenner, and Kurt Rohloff, editors, Financial Cryptography and Data Security - FC 2016 International Workshops, BITCOIN, VOTING, and WAHC, Christ Church, Barbados, February 26, 2016, Revised Selected Papers, volume 9604 of Lecture Notes in Computer Science, pages 19–26. Springer, 2016.
[12]	Vitalik Buterin. Long-range attacks: The serious problem with adaptive proof of work. https://blog.ethereum.org/2014/05/15/long-range-attacks-the-serious-problem-withadaptive-proof-of-work/, 2014.
[13]	Vitalik Buterin. Proof of stake faq. https://github.com/ethereum/wiki/wiki/Proof-of-StakeFAQ, 2016.
[14]	Ran Canetti. Universally composable signature, certification, and authentication. In 17th IEEE Computer Security Foundations Workshop, (CSFW-17 2004), 28-30 June 2004, Pacific Grove, CA, USA, page 219. IEEE Computer Society, 2004.
[15]	David Chaum. Untraceable electronic mail, return addresses, and digital pseudonyms. Commun. ACM, 24(2):84–88, 1981.
[16]	David Chaum. The dining cryptographers problem: Unconditional sender and recipient untraceability. J. Cryptology, 1(1):65–75, 1988.
[17]	George Danezis and Sarah Meiklejohn. Centrally banked cryptocurrencies. In 23nd Annual Network and Distributed System Security Symposium, NDSS 2016, San Diego, California, USA, February 21-24, 2016. The Internet Society, 2016.
[18]	Bernardo Machado David, Peter Gazi, Aggelos Kiayias, and Alexander Russell. Ouroboros praos: An adaptively-secure, semi-synchronous proof-of-stake protocol. IACR Cryptology ePrint Archive, 2017:573, 2017.
[19]	Cynthia Dwork, Nancy A. Lynch, and Larry J. Stockmeyer. Consensus in the presence of partial synchrony. J. ACM, 35(2):288–323, 1988.
[20]	Stefan Dziembowski, Sebastian Faust, Vladimir Kolmogorov, and Krzysztof Pietrzak. Proofs of space. In Rosario Gennaro and Matthew Robshaw, editors, Advances in Cryptology - CRYPTO 2015 - 35th Annual Cryptology Conference, Santa Barbara, CA, USA, August 16-20, 2015, Proceedings, Part II, volume 9216 of Lecture Notes in Computer Science, pages 585–605. Springer, 2015.
[21]	Ittay Eyal and Emin Gun Sirer. Majority is not enough: Bitcoin mining is vulnerable. In Angelos D. Keromytis, editor, Financial Cryptography, volume 7397 of Lecture Notes in Computer Science. Springer, 2014.
[22]	Paul Feldman. A practical scheme for non-interactive verifiable secret sharing. In 28th Annual Symposium on Foundations of Computer Science, Los Angeles, California, USA, 27-29 October 1987, pages 427–437. IEEE Computer Society, 1987.
[23]	Bryan Ford. Delegative democracy. http://www.brynosaurus.com/deleg/deleg.pdf, 2002.
[24]	Juan A. Garay, Aggelos Kiayias, and Nikos Leonardos. The bitcoin backbone protocol: Analysis and applications. In Elisabeth Oswald and Marc Fischlin, editors, Advances in Cryptology - EUROCRYPT 2015 - 34th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Sofia, Bulgaria, April 26-30, 2015, Proceedings, Part II, volume 9057 of Lecture Notes in Computer Science, pages 281–310. Springer, 2015.
[25]	Charles M Grinstead and J Laurie Snell. Introduction to Probability. American Mathematical Society, 2nd edition, 1997.
[26]	Aggelos Kiayias and Giorgos Panagiotakos. Speed-security tradeoffs in blockchain protocols. Cryptology ePrint Archive, Report 2015/1019, 2015. http://eprint.iacr.org/2015/1019.
[27]	Silvio Micali. ALGORAND: the efficient and democratic ledger. CoRR, abs/1607.01341, 2016.
[28]	Tal Moran and Ilan Orlov. Proofs of space-time and rational proofs of storage. Cryptology ePrint Archive, Report 2016/035, 2016. http://eprint.iacr.org/2016/035.
[29]	Rajeev Motwani and Prabhakar Raghavan. Randomized Algorithms. Cambridge University Press, New York, NY, USA, 1995.
[30]	Satoshi Nakamoto. Bitcoin: A peer-to-peer electronic cash system. http://bitcoin.org/bitcoin.pdf, 2008.
[31]	Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani. Algorithmic Game Theory. Cambridge University Press, New York, NY, USA, 2007.
[32]	Karl J. O’Dwyer and David Malone. Bitcoin mining and its energy footprint. ISSC 2014 / CIICT 2014, Limerick, June 26–27, 2014.
[33]	Sunoo Park, Krzysztof Pietrzak, Albert Kwon, Jo¨el Alwen, Georg Fuchsbauer, and Peter Gazi. Spacemint: A cryptocurrency based on proofs of space. IACR Cryptology ePrint Archive, 2015:528, 2015.
[34]	Rafael Pass. Cryptography and game theory. Securty and Cryptography for Networks, 2016, invited talk., 2016.
[35]	Rafael Pass, Lior Seeman, and Abhi Shelat. Analysis of the blockchain protocol in asynchronous networks. IACR Cryptology ePrint Archive, 2016:454, 2016.
[36]	Rafael Pass and Elaine Shi. Fruitchains: A fair blockchain. IACR Cryptology ePrint Archive, 2016:916, 2016.
[37]	Alexander Russell, Cristopher Moore, Aggelos Kiayias, and Saad Quader. Forkable strings are rare. Cryptology ePrint Archive, Report 2017/241, March 2017. http://eprint.iacr.org/ 2017/241.
[38]	Ayelet Sapirshtein, Yonatan Sompolinsky, and Aviv Zohar. Optimal selfish mining strategies in bitcoin. CoRR, abs/1507.06183, 2015.
[39]	Berry Schoenmakers. A simple publicly verifiable secret sharing scheme and its application to electronic voting. In Michael J. Wiener, editor, Advances in Cryptology - CRYPTO ’99, 19th Annual International Cryptology Conference, Santa Barbara, California, USA, August 15-19, 1999, Proceedings, volume 1666 of Lecture Notes in Computer Science, pages 148–164. Springer, 1999.
